# ğŸ“Œ PFM2_Asistente_Compras_Inteligente

## ğŸ“– DescripciÃ³n

Trabajo de fin de mÃ¡ster en **Data Science & IA**.\
Este proyecto consiste en el desarrollo de un **Asistente Inteligente de
Compras**, cuyo objetivo es optimizar la gestiÃ³n de inventario y stock
de una empresa mediante tÃ©cnicas de anÃ¡lisis de datos, simulaciÃ³n de
demanda y modelado predictivo.

------------------------------------------------------------------------

## ğŸ“‚ Estructura del proyecto

ğŸ“‚ PFM2_Asistente_Compras_Inteligente
â”œâ”€â”€ ğŸ“‚ data
â”‚   â”œâ”€â”€ ğŸ“‚ raw
â”‚   â”œâ”€â”€ ğŸ“‚ clean
â”‚   â”‚   â””â”€â”€ supplier_catalog_multi.csv
â”‚   â”œâ”€â”€ ğŸ“‚ processed
â”‚   â”‚   â”œâ”€â”€ demanda_all_adjusted.parquet
â”‚   â”‚   â”œâ”€â”€ demanda_all_adjusted_postnoise.parquet
â”‚   â”‚   â”œâ”€â”€ subset_modelado.parquet
â”‚   â”‚   â”œâ”€â”€ dataset_modelado_ready.parquet
â”‚   â”‚   â”œâ”€â”€ predicciones_2025.parquet
â”‚   â”‚   â”œâ”€â”€ predicciones_2025_estacional.parquet
â”‚   â”‚   â”œâ”€â”€ predicciones_2025_optimista.parquet
â”‚   â”‚   â”œâ”€â”€ predicciones_2025_pesimista.parquet
â”‚   â”‚   â”œâ”€â”€ products.parquet                 # â† Fase 9
â”‚   â”‚   â”œâ”€â”€ suppliers.parquet                # â† Fase 9
â”‚   â”‚   â””â”€â”€ substitutes_unified.parquet      # â† Fase 9
â”‚   â””â”€â”€ ğŸ“‚ external
â”‚
â”œâ”€â”€ ğŸ“‚ outputs
â”‚   â”œâ”€â”€ ğŸ“‚ figuras
â”‚   â””â”€â”€ ğŸ“‚ controles_escenarios
â”‚       â”œâ”€â”€ control_totales_optimista.csv
â”‚       â”œâ”€â”€ control_por_cluster_optimista.csv
â”‚       â”œâ”€â”€ control_totales_pesimista.csv
â”‚       â””â”€â”€ control_por_cluster_pesimista.csv
â”‚
â”œâ”€â”€ ğŸ“‚ reports
â”‚   â””â”€â”€ fase9_validations_summary.json       # â† mÃ©tricas validaciÃ³n F9
â”‚
â”œâ”€â”€ ğŸ“‚ scripts
â”‚   â”œâ”€â”€ ğŸ“‚ eda
â”‚   â”œâ”€â”€ ğŸ“‚ transform
â”‚   â”œâ”€â”€ ğŸ“‚ modeling
â”‚   â”œâ”€â”€ ğŸ“‚ utils
â”‚   â””â”€â”€ ğŸ“‚ export
â”‚       â””â”€â”€ construir_vistas.py              # â† export vistas F9
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks
â”‚   â””â”€â”€ PFM2_Modelado_y_app.ipynb
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt



------------------------------------------------------------------------

## ğŸš€ InstalaciÃ³n

1.  Clonar el repositorio:

    ``` bash
    git clone https://github.com/<usuario>/PFM2_Asistente_Compras_Inteligente.git
    ```

2.  Crear y activar un entorno virtual:

    ``` bash
    python -m venv venv
    source venv/bin/activate  # En Linux/Mac
    venv\Scripts\activate     # En Windows
    ```

3.  Instalar dependencias:

    ``` bash
    pip install -r requirements.txt
    ```

------------------------------------------------------------------------

## ğŸ¯ Objetivos del proyecto

-   SimulaciÃ³n de la demanda base diaria.
-   OptimizaciÃ³n de compras segÃºn stock disponible.
-   IdentificaciÃ³n de proveedores crÃ­ticos.
-   Desarrollo de una interfaz en Streamlit para interactuar con el
    modelo.
-   IntegraciÃ³n futura con SQL para gestiÃ³n eficiente de catÃ¡logos y
    consultas.

------------------------------------------------------------------------

## ğŸ“Š TecnologÃ­as utilizadas

-   **Python**
-   **Pandas / NumPy**
-   **Matplotlib / Seaborn**
-   **Scikit-learn**
-   **Streamlit**
-   **SQLite**
-   **Git / GitHub**

------------------------------------------------------------------------

ğŸ‘‰ A partir de aquÃ­, iremos completando con: 
- **Detalles de datasets** 
- **Proceso metodolÃ³gico (EDA, simulaciones, modelado,validaciÃ³n)** 
- **Resultados** 
- **LÃ­neas futuras**

------------------------------------------------------------------------

La carpeta data/ incluye un README especÃ­fico donde se documenta en detalle la 
estructura de las subcarpetas de datos. Lo mismo ocurre con la carpeta scripts/.

------------------------------------------------------------------------

## ğŸ“‘ MetodologÃ­a â€“ Fase 1 (EDA y preparaciÃ³n de datos)

Durante esta fase se llevaron a cabo las siguientes tareas:

1. **Limpieza y validaciÃ³n de la previsiÃ³n de demanda 2025**  
   - RevisiÃ³n de fechas (inclusiÃ³n de 29/02 y 31/12).  
   - EliminaciÃ³n de nulos y duplicados.  
   - GeneraciÃ³n de reportes automÃ¡ticos de huecos.  

2. **GeneraciÃ³n de histÃ³ricos simulados (2022â€“2024)**  
   - CreaciÃ³n de histÃ³ricos diarios a partir de la previsiÃ³n de 2025.  
   - Ajustes por coherencia temporal y progresiÃ³n lÃ³gica entre aÃ±os.  
   - ExportaciÃ³n en CSV/Parquet y reporte de validaciÃ³n.  

3. **Limpieza del catÃ¡logo de productos**  
   - NormalizaciÃ³n de caracteres y eliminaciÃ³n de inconsistencias.  
   - ReordenaciÃ³n de columnas y exportaciÃ³n en formato limpio.  
   - ExportaciÃ³n final en Excel y Parquet para integraciÃ³n con la demanda.  

4. **AnÃ¡lisis de coherencia entre histÃ³ricos (2022â€“2024)**  
   - **Visual**: evoluciÃ³n mensual y boxplots de medias por producto.  
   - **EstadÃ­stico**: descriptivos (media, std, CV) y correlaciones interanuales (>0.98).  
   - **Contrastes de hipÃ³tesis**: ANOVA y Kruskal-Wallis confirman ausencia de diferencias significativas entre aÃ±os.  

ğŸ“Œ **ConclusiÃ³n de la fase**:  
Los histÃ³ricos generados presentan un comportamiento **estable, coherente y robusto**, validando que los datos estÃ¡n en condiciones Ã³ptimas para pasar a la siguiente fase de desagregaciÃ³n de demanda y modelado predictivo.

------------------------------------------------------------------------

### JustificaciÃ³n del uso de patrones estacionales

Aunque el dataset inicial es artificial, se ha enriquecido mediante la aplicaciÃ³n de un **patrÃ³n estacional basado en factores reales del comercio electrÃ³nico en EspaÃ±a** (ciclos de ingresos mensuales, estacionalidad semanal, campaÃ±as clave como rebajas, Black Friday o Navidad, y ajustes en festivos/vacaciones).  

El objetivo no es replicar al detalle un histÃ³rico pasado, sino **incorporar estructuras realistas** que permitan que los modelos de predicciÃ³n entrenados posteriormente sean **robustos y aplicables a escenarios futuros**.  
De este modo, cada ajuste o modificaciÃ³n sobre el calendario se entiende como una **etapa de calibraciÃ³n deliberada**, cuyo fin es generar un dataset artificial mÃ¡s realista, coherente y predictivo.  

-------------------------------------------------------------------------

##  ğŸ“‘ MetodologÃ­a â€“ Fase 2 (GeneraciÃ³n de histÃ³ricos y validaciÃ³n estacional).

1. **PatrÃ³n estacional**
   - Calendario artificial enriquecido con factores del ecommerce en EspaÃ±a (rebajas, Black Friday, Prime Day, Navidad, Semana Santa, festivos y agosto).
   - La funciÃ³n `generar_calendario_estacional(...)` se aplica por aÃ±o sin I/O y los scripts guardan el calendario por aÃ±o.

2. **DesagregaciÃ³n de demanda anual**
   - ConversiÃ³n a demanda **diaria** para 2022, 2023 y 2024.
   - Entradas: `data/processed/demanda_diaria_YYYY.csv` (columnas: `Date`, `Demand_Day`).
   - Salidas EDA: `outputs/figures/*` y `outputs/tables/*`.

3. **Comparativa entre aÃ±os (EDA)**
   - EvoluciÃ³n diaria total por aÃ±o, medias mensuales con CV, correlaciones interanuales y KPIs de consistencia.

4. **ValidaciÃ³n con calendario real (iterativa)**
   - Objetivo: comprobar si los picos/vales de la demanda desagregada coinciden con eventos reales.
   - Se probaron diferentes enfoques: baseline mensual, filtro de activos, baseline DoW, baseline local Â±k y ventanas desplazadas Â±shift.
   - **ConfiguraciÃ³n final** seleccionada: **baseline local Â±7 con ventanas Â±3**.
   - Salidas:
     - `outputs/tables/validacion_calendario_real_SHIFT_localk7_s3_YYYY.csv`
     - `outputs/tables/validacion_calendario_real_kpis_SHIFT_k7_s3.csv`
     - `outputs/figures/evolucion_2024_con_eventos_SHIFT_k7_s3.png`

ğŸ““ **Nota metodolÃ³gica (validaciÃ³n estacional)**  
Se elaborÃ³ un **Notebook bitÃ¡cora** con todas las iteraciones de validaciÃ³n frente a calendario real.  
Este README y el notebook **PFM2_Fase2** recogen Ãºnicamente la **versiÃ³n final consolidada** (baseline local Â±7 y ventanas Â±3).  
La bitÃ¡cora estÃ¡ disponible en la carpeta `/notebooks/` como material complementario.


### Reproducibilidad (script)

# Desde la raÃ­z del proyecto
python scripts/eda/validacion_calendario_real.py \
  --years 2022 2023 2024 --k 7 --shift 3


ğŸ“Œ ConclusiÃ³n de la Fase 2:
La validaciÃ³n estacional confirma que los histÃ³ricos desagregados reflejan un comportamiento coherente con eventos de mercado. La configuraciÃ³n final 
seleccionada (baseline local Â±7 y ventanas Â±3) se utilizarÃ¡ como feature base en la siguiente fase, donde se integrarÃ¡n variables de precio y externas.

-------------------------------------------------------------------------
## ğŸ“‘ MetodologÃ­a â€“ Fase 3 (Clustering de productos y generaciÃ³n de subset representativo)

### 3.1 PreparaciÃ³n de features de producto
- Limpieza y normalizaciÃ³n de categorÃ­as.
- EliminaciÃ³n de productos sin PCs relevantes (categorÃ­as no representativas).
- ObtenciÃ³n de `productos_features_clean.csv` como base de entrada al anÃ¡lisis de clustering.

### 3.2 Clustering de productos
- ComparaciÃ³n de tÃ©cnicas: **K-Means, GMM y DBSCAN**.
- MÃ©tricas internas: silhouette score (K-Means con *k=4* â‰ˆ 0.32).
- InterpretaciÃ³n de clusters:
  - **C0** â†’ nicho reducido (~210 productos).
  - **C1** â†’ productos estables y de alta demanda (~1.233).
  - **C2** â†’ cluster mayoritario (~3.394).
  - **C3** â†’ miscelÃ¡nea (~1.101).
- DecisiÃ³n final: **K-Means (k=4)** como modelo de referencia.  
  GMM y DBSCAN se emplearon como tÃ©cnicas de contraste.

### 3.3 ValidaciÃ³n complementaria del clustering
- Uso del notebook auxiliar `PFM2_Fase3_pruebas_clustering.ipynb`.
- ConfirmaciÃ³n de la robustez de K-Means frente a alternativas.

### 3.4 AsignaciÃ³n de clusters a la demanda desagregada
- Script `asignar_cluster_a_demanda.py`:
  - **Entrada**: `demanda_filtrada_enriquecida_sin_nans.csv` + `productos_clusters.csv`.
  - **Salida**: `demanda_con_clusters.csv`.
  - ExclusiÃ³n de productos sin cluster asignado (~113 productos, <2%).
- Validaciones:
  - Cobertura temporal completa.
  - AsignaciÃ³n de clusters consistente con el catÃ¡logo.

### 3.5 GeneraciÃ³n del subset representativo
- **Criterios de selecciÃ³n**:
  - Mantener cobertura completa de fechas (2022â€“2024).
  - Conservar casi completos los clÃºsteres minoritarios (C0, C1, C3).
  - Reducir proporcionalmente el clÃºster mayoritario (C2) al ~30%.
  - Incluir **todos los outliers** como casos especiales (no eliminar top ventas atÃ­picos).
- **Outputs intermedios**:
  - `demanda_subset.parquet` (30% sin outliers).
  - `outliers.parquet` (productos con `is_outlier=1`).
  - `demanda_subset_final.parquet` (fusiÃ³n subset + outliers).

### 3.6 Validaciones del subset final
- **ValidaciÃ³n rÃ¡pida pre-outliers**:
  - Reglas de reducciÃ³n de clusters aplicadas correctamente.
  - Integridad de claves sin duplicados ni nulos.
- **ValidaciÃ³n robusta final** (sobre parquet):
  - Cobertura temporal 2022â€“2024 intacta.
  - Sin duplicados ni NaNs en claves.
  - Subset âŠ† catÃ¡logo original.
  - Todos los outliers conservados (220.296 filas, 201 productos).
  - DistribuciÃ³n por cluster coherente tras reducciÃ³n.
  - TamaÃ±o final: 3.596 productos (~60% del catÃ¡logo).


ğŸ“Œ **ConclusiÃ³n de la Fase 3**:  
Se ha construido un **subset representativo, coherente y manejable** (30% + outliers), que mantiene diversidad de clusters, top ventas atÃ­picos y cobertura temporal completa. Este subset servirÃ¡ como base para la **Fase 4**, centrada en el anÃ¡lisis del impacto del precio y variables externas.


-------------------------------------------------------------------------

## ğŸ“‘ MetodologÃ­a â€“ Fase 4 (Impacto del precio sobre la demanda)

### 4.1 Objetivo, datos de partida y diseÃ±o del efecto (ventanas + elasticidades)
- **Objetivo**: simular cÃ³mo cambian las unidades cuando decidimos modificar el precio (descuentos/subidas), manteniendo separados otros efectos (promos no-precio, externos). Se trabaja sobre el subset final (2022â€“2024) y se alinea con el calendario real validado en Fase 2.
- **Datos de partida** (dataset `demanda_subset_final`):
  - Demanda â†’ `Demand_Day`
  - Producto â†’ `Product_ID`
  - Fecha â†’ `Date`
  - ClÃºster â†’ `Cluster`
  - Outliers â†’ `is_outlier`
  - Precio base (si existe) â†’ `precio_medio`  
  > Si no hay serie de precio real, se genera **precio virtual** a partir de las ventanas.
- **Ventanas**: `start`, `end`, `discount` (p. ej. âˆ’0.10), `scope_type` (`global|cluster|product_id`) y `scope_values`.
- **Elasticidades por clÃºster (arranque)**:
  - C0 = âˆ’0.6 (poco sensible)
  - C1 = âˆ’1.0 (media)
  - C2 = âˆ’1.2 (alta)
  - C3 = âˆ’0.8 (media-baja)
- **FÃ³rmula del efecto**  
  Multiplicador de unidades por dÃ­a:  
  `M_price,t = (1 + d_t)^(Îµ_{g(i)})`  â‡’  `qty_{i,t} = baseline_{i,t} * M_price,t`
- **GuardarraÃ­les y polÃ­tica de outliers**
  - **CAP por clÃºster (sin evento)**: C0 1.8Ã—, C1 2.2Ã—, C2 2.8Ã—, C3 2.0Ã—.  
    En dÃ­a de **evento real** (SHIFT) â†’ CAP Ã— **1.5**.
  - **FLOOR** global: **0.5Ã—**.
  - **Outliers**: si `is_outlier==1` y `M>1`, **no amplificar** (forzar `M=1`).  
  - **Solapes**: prioridad `product_id` > `cluster` > `global` (se elige el mayor `|Mâˆ’1|`).


### 4.2 Preflight de ventanas â€” `scripts/analysis/ventanas_precio.py`
- Genera/actualiza **`data/auxiliar/ventanas_precio.csv`** y **`data/auxiliar/preflight_ventanas.xlsx`** (sanity de ventanas).
- Entradas: SHIFT `outputs/tables/validacion_calendario_real_SHIFT_*.csv`.
- Recomendado para revisar coberturas, solapes y â€œliftsâ€ esperados por clÃºster antes de aplicar.


### 4.3 AplicaciÃ³n del efecto â€” `scripts/transform/aplicar_efecto_precio.py`
- **Inputs**: `demanda_subset_final.parquet`, `ventanas_precio.csv`, y SHIFT `outputs/tables/validacion_calendario_real_SHIFT_*.csv`.
- **Outputs**:
  - `data/processed/demanda_price_adjusted.parquet`  
    (aÃ±ade `demand_multiplier`, `Demand_Day_priceAdj`, `price_factor_effective`, `Price_virtual` o `Price_index_virtual`).
  - `outputs/tables/price_calendar.parquet` (calendario de multiplicadores; Ãºtil para la app).


### 4.4 ValidaciÃ³n rÃ¡pida (sanity)
- **Rangos**: `M âˆˆ [0.5, CAPÃ—1.5]` sin valores fuera de tope/suelo.  
- **Cobertura**: % de dÃ­as con `Mâ‰ 1` acorde a duraciÃ³n de campaÃ±as.  
- **Outliers**: si `is_outlier==1` y `M>1` â‡’ `M=1`.  
- **Consistencia**: `price_factor_effective â‰ˆ M^(1/Îµ)` (error â‰ˆ 0).  
- **ClÃºster**: mayor lift en C2, intermedio C1/C3, menor C0 (coherente con elasticidades).



### 4.5 ValidaciÃ³n adicional: alineamiento con calendario real
- Alineamiento precio vs. ventanas (Â±3 dÃ­as): **precision â‰ˆ 1.00** y **recall â‰ˆ 0.67** por aÃ±o.  
  â‡’ todo el efecto cae **dentro** de ventanas; no todas las fechas de ventana se usan (diseÃ±o esperado por umbral/cobertura).
- GrÃ¡ficas anuales: picos/mesetas de la serie ajustada coinciden con zonas sombreadas (rebajas, agosto, BF, Navidad).



**ğŸ“Œ ConclusiÃ³n de la Fase 4**  
Fase 4 **OK**. Dataset listo para el **modelado** y para la app de escenarios (*what-if* de precio).

**â­ï¸ Reproducibilidad (Fase 4)**

```bash
# 1) Ventanas de precio (CSV + preflight)
python scripts/analysis/ventanas_precio.py

# 2) Aplicar efecto precio a la baseline (parquet ajustado + calendario)
python scripts/transform/aplicar_efecto_precio.py


â¡ï¸ **Entradas previas necesarias**
- `data/processed/demanda_subset_final.parquet (de Fases 1â€“3)`.
- SHIFT en `outputs/tables/validacion_calendario_real_SHIFT_*.csv (Fase 2)`.

â¬…ï¸ **Salidas clave**
- `data/auxiliar/ventanas_precio.csv`, `data/auxiliar/preflight_ventanas.xlsx`
- `data/processed/demanda_price_adjusted.parquet`
- `outputs/tables/price_calendar.parquet`

-------------------------------------------------------------------------

## ğŸ“‘ MetodologÃ­a â€“ Fase 5 (Factores externos, ruido y validaciÃ³n)

### 5.1 PreparaciÃ³n de los datos de entrada
- Punto de partida: `data/processed/demanda_price_adjusted.parquet` (output de la Fase 4).
- Columnas clave: `Demand_Day`, `Demand_Final`, `Demand_Final_Noiseds`, `demand_multiplier`, `Factors_Applied`.
- RevisiÃ³n inicial de integridad y consistencia antes de aplicar factores externos.

### 5.2 DefiniciÃ³n de factores externos
- Factores considerados: **inflaciÃ³n, promociones no-precio, competencia, estacionalidad extra y eventos especÃ­ficos** (ej. agosto).
- Cada factor se implementa como columna multiplicadora `M_factor`, aplicada sobre la serie de referencia.
- Se evita solapamiento con el precio (ya ajustado en Fase 4).
- Se aÃ±aden tolerancias y ventanas alineadas al calendario real validado en Fase 2.

### 5.3 DiseÃ±o del modelo de aplicaciÃ³n
- FÃ³rmula general de la demanda ajustada: Demand_Final = Demand_Day Ã— (Î  M_factor_i)
- Cuando ningÃºn factor aplica â†’ `Demand_Final = Demand_Day`.
- En cada fila se registra en `Factors_Applied` la lista exacta de factores activos.
- Esta trazabilidad permite auditar el efecto de cada multiplicador.

### 5.4 ImplementaciÃ³n en cÃ³digo
- Scripts principales:
- `ventanas_externos.py` â†’ genera ventanas externas (`calendar_externos.parquet`).
- `enriquecer_ventas_externos.py` â†’ aplica y valida ventanas externas (sanity checks).
- `aplicar_factores.py` â†’ aplica los multiplicadores a la demanda.
- Outputs intermedios:  
- `data/auxiliar/ventanas_externos.csv`, `preflight_externos.xlsx`
- `data/processed/demanda_all_adjusted.parquet`, `calendar_total_externos.parquet`

### 5.5 ValidaciÃ³n de coherencia y robustez.

**5.5.1 ValidaciÃ³n de coherencia del precio**  
- RevisiÃ³n de rangos de multiplicadores (`M âˆˆ [0.5, CAPÃ—1.5]`).
- ConfirmaciÃ³n de que los valores son consistentes con elasticidades y ventanas de Fase 4.

**5.5.2 ValidaciÃ³n adicional (alineamiento ventanas)**  
- ComparaciÃ³n con el calendario real Â±3 dÃ­as.  
- MÃ©tricas: *Precision* = 1.0; *Recall* â‰ˆ 0.67â€“0.69; *F1* â‰ˆ 0.80.  
- GrÃ¡ficas muestran picos alineados con ventanas de rebajas, agosto, Black Friday, etc.

**5.5.3. Comparativa de demanda.**  
- IntroducciÃ³n de ruido lognormal para enriquecer la serie y aumentar la variabilidad de forma controlada.  
- La comparativa entre `Demand_Day`, `Demand_Final` y `Demand_Final_Noiseds` mostrÃ³ que algunos clÃºsters presentaban un 
  exceso de ruido (40â€“60%), mientras que otros mantenÃ­an niveles razonables (~20%).  
- Para estabilizar la serie se aplicÃ³ un ajuste por clÃºster (`ajuste_ruido_por_cluster.py`), reduciendo los casos con exceso a ~22% y 
  manteniendo sin cambios los clÃºsters ya estables.  
- El resultado es un dataset mÃ¡s realista y consistente, que conserva la seÃ±al original pero mejora la 
  robustez para el modelado predictivo.

**5.5.4 ValidaciÃ³n de trazabilidad**  
- ConfirmaciÃ³n de que `Factors_Applied` refleja exactamente los multiplicadores â‰  1.  
- Top combinaciones:  
- `inflation|seasonExtra` (~3.2M filas)  
- `agosto_nonprice|inflation|seasonExtra` (~334K filas)  
- `inflation|promo|seasonExtra` (~237K filas)  
- Se confirma que no aparecen factores espurios ni inconsistencias.

ğŸ“Œ **ConclusiÃ³n de la Fase 5**:  
La demanda ajustada resultante es **estadÃ­sticamente coherente, trazable y alineada con el calendario real**, constituyendo una base sÃ³lida para la siguiente fase de **modelado predictivo**.

-------------------------------------------------------------------------

## ğŸ“‘ MetodologÃ­a â€“ Fase 6 (AnÃ¡lisis y tratamiento de outliers)

### 6.1 ValidaciÃ³n complementaria (`is_outlier = 0`)
- Punto de partida: `data/processed/demanda_all_adjusted_postnoise.parquet`.
- Criterios aplicados: MAD z-score y percentiles P95/P99.
- ClasificaciÃ³n automÃ¡tica: top_venta, pico_aislado, mixto.
- Outputs:
  - `reports/outliers/outliers_candidatos_nuevos_dias.csv`
  - `reports/outliers/outliers_candidatos_nuevos_productos.csv`

### 6.2 RevisiÃ³n de outliers DBSCAN (`is_outlier = 1`)
- Se aplica la misma lÃ³gica que en 6.1 sobre los casos detectados inicialmente con DBSCAN.
- ClasificaciÃ³n y decisiones por producto-aÃ±o.
- Outputs:
  - `reports/outliers/outliers_dbscan_dias.csv`
  - `reports/outliers/outliers_dbscan_productos.csv`

### 6.3 Consolidado y decisiones finales
- UniÃ³n y priorizaciÃ³n de tipologÃ­as: top_venta > mixto > pico_aislado.
- Decisiones aplicadas: sin_cambio, suavizado_a015, alerta_pendiente.
- Outputs:
  - `reports/outliers/outliers_resumen.csv`
  - `reports/outliers/outliers_resumen_metricas.csv`

### 6.4 Implicaciones para modelado y subset final
- Se mantiene la columna original is_outlier (DBSCAN).
- Se aÃ±aden columnas de trazabilidad anual:
  - `tipo_outlier_year`
  - `decision_outlier_year`
- Output final:
  -`data/processed/subset_modelado.parquet`

ğŸ“Œ  **ConclusiÃ³n de la Fase 6**.
Los picos aislados quedan justificados por calendario real y los top ventas se mantienen; no se detectan outliers espurios. El dataset resultante estÃ¡ validado y listo para la Fase 7 (modelado y aplicaciÃ³n).

-------------------------------------------------------------------------

## ğŸ“‘ MetodologÃ­a â€“ Fase 7 (ValidaciÃ³n y preparaciÃ³n del dataset para modelado)

### 7.1 ValidaciÃ³n inicial del dataset
- Script principal: `scripts/eda/validacion_dataset_modelado.py`
- Objetivos:
  - Verificar integridad del target (`demand_final_noised`).
  - Confirmar cobertura temporal completa (2022â€“2024).
  - Detectar duplicados en (`product_id`, `date`).
  - Validar la coherencia de los clÃºsteres y la trazabilidad de los outliers.
  - Generar reporte tipo â€œsemÃ¡foroâ€ con indicadores crÃ­ticos (OK/NO-OK).
- Script auxiliar: `scripts/eda/check_outliers_clusters.py`
  - Objetivo: auditar la coherencia entre `cluster` y `__cluster__` y confirmar la asignaciÃ³n de outliers.
  - Se documenta como herramienta complementaria, no obligatoria en el pipeline.
- Resultados:
  - Target sin nulos ni negativos.
  - Cobertura temporal completa hasta 2024-12-31.
  - Sin duplicados por (`product_id`, `date`).
  - Todos los productos con clÃºster asignado (0â€“3).
  - Outliers asignados al clÃºster mayoritario, garantizando cobertura.
- ConclusiÃ³n: el dataset `subset_modelado.parquet` queda validado como punto de partida fiable para el modelado.


### 7.2 PreparaciÃ³n del dataset para modelado
- Script: `scripts/transform/preparacion_dataset_modelado.py`
- Transformaciones aplicadas:
  - Renombrado de columnas clave:
    - `__cluster__` â†’ `cluster_id`
    - `demand_final_noised` â†’ `sales_quantity`
  - EliminaciÃ³n de columnas redundantes:
    - `cluster`, `__product_id__`, `demand_final_noiseds_adj`
  - NormalizaciÃ³n de tipos:  
    - `date` â†’ datetime  
    - `product_id` â†’ string  
    - `cluster_id` â†’ int
  - Control de duplicados y nulos:
    - Sin duplicados en (`product_id`, `date`)  
    - Sin nulos en `sales_quantity`
  - SelecciÃ³n final de variables: identificadores, target, precio, factores externos y trazabilidad.
- Output final:  
  - `data/processed/dataset_modelado_ready.parquet` â†’ dataset limpio y consolidado para modelado.
- VerificaciÃ³n post-transformaciÃ³n:
  - Confirmada cobertura temporal completa.  
  - `sales_quantity` sin nulos ni negativos.  
  - `product_id` vÃ¡lido (sin 0 ni cadenas vacÃ­as).  
  - Sin duplicados en (`product_id`, `date`).  
  - `cluster_id` completo y dentro del rango esperado (0â€“3).  


### 7.3 Target y features disponibles
- **Target definido:**
  - `sales_quantity` â†’ demanda diaria final por producto, consolidada y validada.
- **Features disponibles:**
  - Identificadores y estructura temporal:
    - `product_id`, `date`, `cluster_id`
  - Precio y derivados:
    - `precio_medio`, `price_virtual`, `price_factor_effective`, `demand_day_priceadj`
  - Factores externos:
    - `m_agosto_nonprice`, `m_competition`, `m_inflation`, `m_promo`, etc.
  - Outliers y trazabilidad (opcionales):
    - `is_outlier`, `tipo_outlier_year`, `decision_outlier_year`
- Implicaciones:
  - Los modelos de series temporales clÃ¡sicos (p.ej. SARIMAX, Holt-Winters) usarÃ¡n el target y exÃ³genas seleccionadas.
  - Los modelos de machine learning (Ridge, Random Forest) podrÃ¡n explotar un conjunto mÃ¡s amplio de features.
  - Este listado define el universo de variables disponibles, dejando la selecciÃ³n especÃ­fica para la Fase 8.

ğŸ“Œ **ConclusiÃ³n de la Fase 7**:  
El dataset `dataset_modelado_ready.parquet` constituye la **base estable, homogÃ©nea y trazable** para el modelado.  
Con esta fase se cierra todo el bloque de preparaciÃ³n y se garantiza que los modelos de la Fase 8 se entrenarÃ¡n sobre datos limpios, validados y estructurados.

-------------------------------------------------------------------------
ğŸ“‘ MetodologÃ­a â€“ Fase 8 (Modelado de la demanda).

### 8.1 PreparaciÃ³n del dataset para entrenamiento
- **Script principal:** `scripts/eda/preparacion_dataset_ml.py`
- **Objetivos:**
  - Preparar el dataset `dataset_modelado_ready.parquet` como entrada para modelos de series temporales y de ML.
  - Asegurar consistencia en el target (`sales_quantity`) y en las features seleccionadas.
- **Resultados:**
  - Dataset preparado y verificado como base comÃºn para los experimentos de modelado.
- **ConclusiÃ³n:** El dataset queda listo para entrenar modelos bajo diferentes enfoques.



### 8.2 Baselines
- **Scripts principales:**  
  - `scripts/modeling/seasonal_naive.py`  
  - `scripts/modeling/holt_winters.py`  
- **Objetivos:**
  - Establecer modelos de referencia iniciales (benchmarks).
  - Evaluar enfoques sencillos: baseline por clÃºster, Seasonal Naive y Holt-Winters (ETS).
- **Resultados:**
  - Se generan mÃ©tricas de error para cada baseline.
  - Se confirma que los modelos clÃ¡sicos capturan cierta estacionalidad pero no son robustos en clÃºsteres con alta variabilidad.
- **ConclusiÃ³n:** Es necesario avanzar hacia modelos mÃ¡s complejos para mejorar precisiÃ³n y estabilidad.


### 8.3 Modelos clÃ¡sicos de series temporales
- **Script principal:** `scripts/modeling/sarimax_cluster.py`
- **Objetivos:**
  - Entrenar y evaluar modelos SARIMAX por clÃºster.
  - Incluir factores exÃ³genos relevantes en la predicciÃ³n.
- **Resultados:**
  - SARIMAX obtiene resultados aceptables en clÃºsteres estables.
  - En clÃºsteres mÃ¡s variables, el modelo presenta limitaciones.
- **ConclusiÃ³n:** SARIMAX aporta valor pero no ofrece mejoras consistentes frente a los baselines en todos los casos.


### 8.4 Modelos de regresiÃ³n y ML
- **Scripts principales:**  
  - `scripts/modeling/regresion_ml.py`  
  - `scripts/modeling/evaluacion_global.py`  
- **Objetivos:**
  - Aplicar modelos de regresiÃ³n y Random Forest para capturar relaciones no lineales.
  - Comparar el rendimiento frente a SARIMAX y baselines.
  - Analizar la importancia de variables y su interpretabilidad.
- **Resultados:**
  - Random Forest ofrece los mejores resultados globales.
  - Se identifican como variables clave: precio medio, promociones y factores externos.
- **ConclusiÃ³n:** Random Forest se establece como el modelo mÃ¡s adecuado para este caso de uso.


### 8.5 Backtesting y comparaciÃ³n
- **Script principal:** `scripts/modeling/backtesting.py`
- **Objetivos:**
  - Validar los modelos mediante backtesting.
  - Comparar mÃ©tricas globales y por clÃºster (WAPE, MAPE, RMSE).
- **Resultados:**
  - Random Forest mantiene un rendimiento mÃ¡s estable frente a SARIMAX y baselines.
- **ConclusiÃ³n:** El modelo seleccionado es consistente bajo distintos periodos de validaciÃ³n.


### 8.6 Predicciones finales (2025) â€“ escenario neutro con estacionalidad
- **Script principal:** `scripts/modeling/predicciones_2025.py`
- **Objetivos:**
  - Generar el escenario neutro estacionalizado para 2025.
  - Establecer una base de comparaciÃ³n para escenarios alternativos.
- **Resultados:**
  - Se produce el archivo `predicciones_2025_estacional.parquet`.
- **ConclusiÃ³n:** El escenario neutro estacionalizado queda validado como baseline para simulaciones.


### 8.7 SimulaciÃ³n de escenarios optimista y pesimista
- **Scripts principales:**  
  - `scripts/utils/simular_escenario.py`  
  - `scripts/modeling/simular_escenario_optimista.py`  
  - `scripts/modeling/simular_escenario_pesimista.py`  
- **Objetivos:**
  - Simular escenarios alternativos aplicando factores derivados de las mÃ©tricas de backtesting.
  - Optimista: multiplicar predicciones por `1 + WAPE_%`.
  - Pesimista: multiplicar predicciones por `1 - WAPE_%` (con lÃ­mite â‰¥ 0).
- **Resultados:**
  - Escenarios alternativos generados en formato Parquet (`predicciones_2025_optimista.parquet`, `predicciones_2025_pesimista.parquet`).
  - Controles comparativos exportados en CSV (`outputs/controles_escenarios`).
- **ConclusiÃ³n:** Los escenarios reflejan un rango realista de incertidumbre basado en la precisiÃ³n histÃ³rica del modelo.


### 8.8 Conclusiones y lÃ­neas futuras
- **Conclusiones:**
  - Random Forest se confirma como el modelo mÃ¡s robusto para predecir la demanda base.
  - El backtesting valida la coherencia del escenario neutro y los escenarios alternativos.
  - El enfoque por clÃºster resulta clave para capturar patrones diferenciados.
- **LÃ­neas de mejora:**
  - Probar otros modelos avanzados (Prophet, LSTM).
  - Refinar la simulaciÃ³n de factores externos (exÃ³genas).
  - Incorporar un mÃ³dulo de ajuste manual para eventos extraordinarios.



ğŸ“Œ **ConclusiÃ³n de la Fase 8**:  
La Fase 8 consolida el bloque de modelado, confirmando que Random Forest es el modelo mÃ¡s robusto para predecir la demanda. El backtesting valida la coherencia del escenario neutro y de los escenarios alternativos, asegurando un rango realista de proyecciones. Se cierra asÃ­ la fase de modelado con una base sÃ³lida para la toma de decisiones en compras y planificaciÃ³n.

-------------------------------------------------------------------------
## ğŸ“‘ MetodologÃ­a â€“ Fase 9 (CatÃ¡logo multiproveedor y sustitutos + export)

### 9.1 Objetivo
Enriquecer el catÃ¡logo con **proveedores alternativos** y validar reglas clave antes de exportar las **vistas** que consumirÃ¡ la app de Streamlit (la explicaciÃ³n de Streamlit va en su apartado propio).

### 9.2 Datos de entrada
- `data/processed/preferred_supplier.csv`  (proveedor preferente por `product_id`)
- `data/clean/supplier_catalog_multi.csv`  (catÃ¡logo con candidatos alternativos)
- `data/clean/substitutes.csv`             (sustitutos por similitud de producto)

### 9.3 Validaciones multiproveedor
Se realizan sobre el cruce `preferred_supplier` + `supplier_catalog_multi`:

- **V1 Proveedor distinto**: el alternativo nunca coincide con el preferente.  
- **V2 Precio modificado**: `precio_alt` difiere de `precio_pref` (tolerancia Â±0.5%).  
- **V3 Stock modificado**: `disponibilidad_alt` â‰  `disp_pref` (se permite 0 para simular rotura).  
- **V4 Lead time bucket**: coherente con `lead_time` (`2-4`, `5-7`, `10-15`).  

Las validaciones son duras: si alguna falla se muestra una muestra de filas y **se corta** la ejecuciÃ³n.

**Salida de control**: `reports/fase9_validations_summary.json` (mÃ©tricas agregadas).

### 9.4 Esquema de salida (para la app)
> Este bloque es **documentaciÃ³n**: no altera la app ni sus inputs.

- **products**: `product_id`, `categoria`, `pack_size`, `uom`, `precio_medio`  
- **suppliers**: `product_id`, `supplier_id`, `prioridad`, `precio`, `disponibilidad`, `lead_time`  
- **substitutes**: `product_id`, `sustituto_id`, `score`, `categoria`

### 9.5 Export de vistas (consumo por Streamlit)
Script: `scripts/export/construir_vistas.py`

**Salidas**
- `data/processed/products.parquet`  
- `data/processed/suppliers.parquet`  
- `data/processed/substitutes_unified.parquet`  

### 9.6 Reproducibilidad (Fase 9)
```bash
# Desde la raÃ­z del repo
python scripts/export/construir_vistas.py

ğŸ“Œ ConclusiÃ³n de la Fase 9
CatÃ¡logo multiproveedor validado (V1â€“V4) y vistas exportadas para la app.
-------------------------------------------------------------------------
## ğŸ“‘ MetodologÃ­a â€“ Fase 10 (Motor de movimientos de stock)

### 10.1 Objetivo
Desarrollar un **procesador de movimientos de stock** que actualice el inventario en funciÃ³n de pedidos de cliente, genere ledger de movimientos, dispare alertas y sugiera Ã³rdenes de compra, incluyendo el manejo de sustitutos.

### 10.2 Datos de entrada
- `data/clean/Inventario.csv` (inventario inicial; columnas: Product_ID, Proveedor, Nombre, Categoria, Stock Real).  
- `customer_orders.csv` (pedidos simulados; columnas: date, item_id, qty).  
- `supplier_catalog.csv` (catÃ¡logo enriquecido con precio, lead_time, moq, mÃºltiplo).  
- `service_policy.csv` (polÃ­ticas de cobertura y stock de seguridad por categorÃ­a).  
- `substitutes.csv` (sustitutos internos y externos por Product_ID).  

### 10.3 LÃ³gica implementada
1. **Carga y validaciÃ³n de inventario y pedidos**.  
   - Control de columnas obligatorias y formatos.  
   - Posibilidad de generar pedidos DEMO en ausencia de input.  

2. **Enriquecimiento con catÃ¡logos y polÃ­ticas**.  
   - Merge con catÃ¡logo multiproveedor y polÃ­tica de servicio.  
   - Fallbacks: cobertura=14 dÃ­as, lead_time=5 dÃ­as, SS=0 uds.  

3. **CÃ¡lculo de mÃ©tricas base**.  
   - Demanda media diaria (`Î¼_d`).  
   - Reorder Point (ROP = Î¼_dÂ·LT + SS).  

4. **Procesado de pedidos**.  
   - ActualizaciÃ³n secuencial de `stock_actual`.  
   - Ledger cronolÃ³gico de movimientos (ventas, recepciones).  
   - GeneraciÃ³n de alertas (WARN, CRIT) ante inconsistencias o roturas.  

5. **Etiquetado y sugerencias de compra**.  
   - Flags `flag_rotura` y `flag_bajo`.  
   - CÃ¡lculo de `qty_sugerida` con validaciÃ³n de MOQ y mÃºltiplos.  
   - CÃ¡lculo de importes (`qty_sugerida` Ã— `precio`).  

6. **Sustitutos**.  
   - BÃºsqueda de hasta 3 alternativas por SKU en rotura.  
   - Filtros por disponibilidad y ranking por score.  
   - Alertas crÃ­ticas si no se encuentran sustitutos.  

7. **Ã“rdenes de compra**.  
   - GeneraciÃ³n de cabecera y lÃ­neas por proveedor.  
   - Control de motivo (rotura/bajo stock) y trazabilidad en ledger.  

### 10.4 Salidas
- `inventory_updated.csv` â†’ inventario vivo post-pedidos.  
- `ledger_movimientos.csv` â†’ histÃ³rico de movimientos.  
- `alerts.csv` â†’ alertas generadas.  
- `sugerencias_compra.csv` â†’ candidatos a reaprovisionamiento.  
- `ordenes_compra.csv` y `ordenes_compra_lineas.csv` â†’ Ã³rdenes agrupadas por proveedor.  
- `sugerencias_sustitutos.csv` â†’ propuestas de sustitutos para roturas.  

### 10.5 ValidaciÃ³n
- Reglas aplicadas: stock â‰¥ 0, qty > 0 en pedidos, ROP coherente con Î¼_d y lead_time.  
- Se verificÃ³ consistencia de salidas y ausencia de NaNs crÃ­ticos.  
- AnÃ¡lisis de resultados: detecciÃ³n correcta de roturas y bajo ROP, ledger cronolÃ³gico sin inconsistencias, sustitutos sugeridos para >85% de SKUs en rotura.

ğŸ“Œ **ConclusiÃ³n de la Fase 10**  
El motor de movimientos de stock queda consolidado: actualiza inventario, mantiene trazabilidad con ledger, dispara alertas y genera sugerencias de compra junto con sustitutos y Ã³rdenes de compra. Sus salidas alimentan directamente la app en Streamlit.

**â­ï¸ Reproducibilidad (Fase 10)**

```bash
# Desde la raÃ­z del repo
python scripts/operativa/movimientos_stock.py \
  --inventario data/clean/Inventario.csv \
  --orders data/clean/customer_orders.csv \
  --supplier-catalog data/clean/supplier_catalog.csv \
  --service-policy data/clean/service_policy.csv \
  --substitutes data/clean/substitutes.csv \
  --outdir data/processed/fase10_stock

-------------------------------------------------------------------------

## ğŸ“‘ MetodologÃ­a â€“ Fase 11 (Despliegue en Streamlit â€” SupplyMind)

### 11.1 Objetivo
Desplegar el asistente de compras en una **app interactiva en Streamlit**, conectando las salidas de la Fase 10 con una interfaz usable para el tÃ©cnico de compras.

### 11.2 Bloques principales de la app
1. **Home**: portada con navegaciÃ³n mediante tarjetas a las distintas secciones.  
2. **ExploraciÃ³n & Sustitutos**: consulta de inventario vivo y sustitutos unificados, con ediciÃ³n opcional de pedidos UI y acceso a ledger, Ã³rdenes y alertas.  
3. **Proveedores**: vista por proveedor con catÃ¡logo, precios y anÃ¡lisis de histÃ³ricos 2023â€“2025 (ranking y tendencias).  
4. **Movimientos de stock**: inventario vivo con flags de rotura/bajo ROP, buscador y filtrado por proveedor/categorÃ­a.  
5. **Reapro / Pedidos**: consolidaciÃ³n de sugerencias, gestiÃ³n de Ã³rdenes en curso y recibidas, y simulador de escenarios de demanda.  
6. **Mensajes y descargas**: alertas INFO/WARN/CRIT alineadas con `alerts.csv` y botones para descargar CSVs.  

### 11.3 Datos consumidos
- Outputs de Fase 10 (`inventory_updated.csv`, `ledger_movimientos.csv`, `alerts.csv`, `sugerencias_compra.csv`, `ordenes_compra*.csv`, `sugerencias_sustitutos.csv`).  
- Vistas de catÃ¡logo multiproveedor (`products.parquet`, `suppliers.parquet`, `substitutes_unified.parquet`).  
- Predicciones 2025 (`predicciones_2025*.parquet`) para el simulador.  

### 11.4 Validaciones de la app
- Se verificÃ³ coherencia en la carga de CSV/Parquet y alineaciÃ³n de nombres de columnas (`Product_ID` vs `item_id`).  
- La navegaciÃ³n mantiene el estado entre secciones gracias a `st.session_state`.  
- Se comprobÃ³ la descarga correcta de archivos y la consistencia de mensajes de alerta.  
- El simulador reproduce escenarios alternativos coherentes con los definidos en Fase 8.  

ğŸ“Œ **ConclusiÃ³n de la Fase 11**  
La app en Streamlit convierte SupplyMind en un **asistente operativo**: permite visualizar inventario y alertas, gestionar sustitutos y multiproveedor, generar y recibir Ã³rdenes, y simular escenarios de demanda. Con ello, el proyecto culmina en una herramienta prÃ¡ctica y directamente utilizable en el Ã¡rea de compras.
