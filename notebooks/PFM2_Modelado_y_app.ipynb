{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f514c496",
   "metadata": {},
   "source": [
    "# **PFM2 ‚Äì Modelado y Aplicaci√≥n Pr√°ctica.**\n",
    "\n",
    "### Punto de partida\n",
    "Este notebook contin√∫a directamente el trabajo realizado en las Fases 1‚Äì6, utilizando como insumo el dataset validado `data/processed/subset_modelado.parquet`.  \n",
    "Dicho dataset incluye:  \n",
    "- La demanda original y ajustada.  \n",
    "- La etiqueta `is_outlier` (procedente de DBSCAN).  \n",
    "- Las nuevas columnas de trazabilidad anual (`tipo_outlier_year` y `decision_outlier_year`) generadas en la Fase 6.  \n",
    "\n",
    "Este punto de partida garantiza que el modelado se apoya sobre datos consistentes, libres de anomal√≠as espurias y con informaci√≥n de contexto suficiente para interpretar se√±ales de negocio.\n",
    "\n",
    "### Objetivo\n",
    "Entrenar y evaluar modelos de predicci√≥n de demanda robustos, comparando diferentes enfoques (modelos estad√≠sticos, machine learning y enfoques h√≠bridos) y evaluando su capacidad para:  \n",
    "- Integrar se√±ales clave como top ventas y eventos de calendario.  \n",
    "- Capturar tendencias, estacionalidades y picos de forma coherente.  \n",
    "- Servir como base para la construcci√≥n de una aplicaci√≥n interactiva en **Streamlit**, que permita al usuario explorar, simular y consumir las previsiones en un entorno operativo.  \n",
    "\n",
    "### Referencia metodol√≥gica\n",
    "Para una descripci√≥n detallada del tratamiento de outliers y validaciones aplicadas, ver `reports/outliers/outliers_resumen.csv` y el notebook de Fase 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e969309",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc8b99",
   "metadata": {},
   "source": [
    "### **√çndice de Contenidos**\n",
    "\n",
    "#### Fase 7: Validaci√≥n y preparaci√≥n del dataset para el modelado.\n",
    "- 7.1. Validaci√≥n inicial y del dataset.\n",
    "- 7.2. Preparaci√≥n de los datos para el modelado.\n",
    "- 7.3. Target y features disponibles.\n",
    "\n",
    "\n",
    "#### Fase 2: Desagregaci√≥n de los datos\n",
    "- 2.1. Generaci√≥n del patr√≥n estacional para la desagregaci√≥n de la demanda.\n",
    "  - 2.1.1. Aplicaci√≥n del patr√≥n estacional por a√±o (2022‚Äì2024).\n",
    "  - 2.1.2. Validaci√≥n del calendario estacional.\n",
    "- 2.2. Aplicaci√≥n del patr√≥n estacional a la demanda anual.\n",
    "  - 2.2.1. Desagregaci√≥n diaria del a√±o 2024.\n",
    "  - 2.2.2. Desagregaci√≥n diaria del a√±o 2023.\n",
    "  - 2.2.3. Desagregaci√≥n diaria del a√±o 2022.\n",
    "  - 2.2.4. Conclusiones de la desagregaci√≥n de demanda diaria.\n",
    "- 2.3. Comparativa entre a√±os: ¬øse ha aplicado bien la estacionalidad?\n",
    "  - 2.3.1. Evoluci√≥n diaria total por a√±o (curva cruda + suavizada).\n",
    "  - 2.3.2.  Correlaci√≥n de las curvas diarias agregadas (2022‚Äì2024).\n",
    "  - 2.3.3. Demanda media diaria mensual por a√±o.\n",
    "  - 2.3.4. KPIs de consistencia (CV mensual y correlaciones).\n",
    "  - 2.3.5. Validaci√≥n extra con calendario real (Espa√±a 2022‚Äì2024).\n",
    "  - 2.3.6. Conclusiones de la validaci√≥n estacional y configuraci√≥n definitiva.\n",
    "\n",
    "#### Fase 3: Construcci√≥n del subset representativo.\n",
    "- 3.1. Unificaci√≥n de demandas (2022‚Äì2024).\n",
    "- 3.2. Cruce con cat√°logo y asociaci√≥n de categor√≠as.\n",
    "- 3.3. Filtrado de casos problem√°ticos.\n",
    "- 3.4. Reducci√≥n de dimensionalidad (PCA sobre categor√≠as).\n",
    "- 3.5. Clustering de productos.\n",
    "- 3.6. Generaci√≥n del subset representativo.\n",
    "\n",
    "#### Fase 4: Impacto del precio sobre la demanda.\n",
    "- 4.1. Objetivo, datos de partida y mapeo de columnas y dise√±os del efecto precio (ventanas + elasticidades).\n",
    "- 4.2. Preflight de ventanas ‚Äî `ventanas_precio.py`\n",
    "- 4.3. Aplicaci√≥n del efecto ‚Äî `aplicar_efecto_precio.py`\n",
    "- 4.4. Validaci√≥n r√°pida (sanity).\n",
    "- 4.5. Validaci√≥n adicional: alineamiento con calendario real.\n",
    "\n",
    "#### Fase 5: Aplicaci√≥n de factores externos y simulaci√≥n de escenarios.\n",
    "- 5.1. Introducci√≥n y objetivos.\n",
    "- 5.2. Definici√≥n de factores externos.\n",
    "- 5.3. Dise√±o del modelo de aplicaci√≥n.\n",
    "- 5.4. Implementaci√≥n en c√≥digo.\n",
    "- 5.5. Validaci√≥n de coherencia y robustez.\n",
    "  - 5.5.1. Validaci√≥n de coherencia del precio.\n",
    "  - 5.5.2. Validaci√≥n adicional (alineamiento ventanas).\n",
    "  - 5.5.3. Comparativa de demanda.\n",
    "  - 5.5.4. Validaci√≥n de trazabilidad.\n",
    "- 5.6. Conclusiones de la fase 5.\n",
    "\n",
    "#### Fase 6: An√°lisis y tratamiento de outliers.\n",
    "- 6.1. Validaci√≥n complementaria: b√∫squeda de nuevos candidatos.\n",
    "- 6.2. An√°lisis de outliers detectados por DBSCAN.\n",
    "- 6.3. Resultados consolidados y decisiones finales.\n",
    "- 6.4. Implicaciones para el modelado.\n",
    "  - 6.4.1. Integraci√≥n en el subset final.\n",
    "  - 6.4.2. Visualizaci√≥n del impacto de outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e21050",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4521e8",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Nota metodol√≥gica sobre los datos hist√≥ricos utilizados.**\n",
    "\n",
    "Los datos hist√≥ricos correspondientes a los ejercicios 2022‚Äì2024 no proceden de registros reales de ventas, sino que fueron **generados a partir de la previsi√≥n de demanda 2025**. \n",
    "Para construir estos hist√≥ricos se aplicaron de manera controlada diversos componentes que reflejan el comportamiento esperado en un contexto de comercio electr√≥nico:\n",
    "\n",
    "- **Patr√≥n estacional**: incorporaci√≥n de estacionalidad diaria y anual (ciclos de ingresos mensuales, rebajas, campa√±as como Black Friday, Prime Day, etc.).\n",
    "\n",
    "- **Impacto del precio**: simulaci√≥n del efecto del precio sobre la demanda, con distinta sensibilidad por cl√∫ster de producto.\n",
    "\n",
    "- **Factores externos**: inclusi√≥n de variables de calendario y eventos promocionales como dummies ex√≥genas.\n",
    "\n",
    "- **Ruido controlado y aleatorio**: a√±adido de perturbaciones aleatorias con distribuci√≥n normal, calibradas para introducir variabilidad sin distorsionar las tendencias de fondo.\n",
    "\n",
    "> Este enfoque busc√≥ **evitar la circularidad** inherente a la construcci√≥n de hist√≥ricos a partir de una previsi√≥n futura, de manera que los modelos no aprendan relaciones deterministas y conserven capacidad de generalizaci√≥n.\n",
    "\n",
    "üõë **Limitaciones**\n",
    "\n",
    "No obstante, este planteamiento presenta ciertas limitaciones que deben ser tenidas en cuenta en la interpretaci√≥n de los resultados:\n",
    "\n",
    "- Los datos de 2022‚Äì2024 heredan en gran medida las tendencias y estacionalidades de la previsi√≥n 2025, lo que puede reducir la \n",
    "  diversidad de patrones respecto a hist√≥ricos reales.\n",
    "\n",
    "- El ruido introducido, aunque aleatorio, no refleja en su totalidad la complejidad de desviaciones reales  \n",
    "  (errores humanos, incidencias log√≠sticas, cambios imprevistos de mercado).\n",
    "\n",
    "- La validaci√≥n mediante backtesting sobre 2024 se realiza frente a un hist√≥rico simulado a partir de 2025, lo que podr√≠a generar resultados \n",
    "  algo m√°s optimistas que en un entorno con datos 100% reales.\n",
    "\n",
    "üîç **Enfoque adoptado**\n",
    "\n",
    "A pesar de estas limitaciones, el enfoque es **v√°lido y adecuado** para los objetivos del proyecto porque:\n",
    "\n",
    "- Permite **evaluar de manera realista la metodolog√≠a de predicci√≥n y el pipeline completo**(desde la generaci√≥n de features hasta la selecci√≥n de modelos).\n",
    "\n",
    "- Introduce suficiente variabilidad y ruido para que los algoritmos deban **aprender patrones** y no simplemente replicar la previsi√≥n original.\n",
    "\n",
    "- Facilita la comparaci√≥n objetiva entre diferentes familias de modelos y la selecci√≥n por cl√∫ster en base a m√©tricas robustas (sMAPE, WAPE, MAE ponderado).\n",
    "\n",
    "> En conclusi√≥n, los hist√≥ricos generados proporcionan un marco de prueba **coherente y consistente** para validar la l√≥gica del sistema de predicci√≥n y simulaci√≥n de stock, \n",
    "entendiendo que los resultados no equivalen a un backtesting sobre datos 100% reales, sino a un escenario controlado que reproduce condiciones veros√≠miles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b147c5",
   "metadata": {},
   "source": [
    "üìå **Nota metodol√≥gica final sobre outliers y clusters**\n",
    "\n",
    "En la Fase 2, a partir del clustering con DBSCAN, un conjunto reducido de productos qued√≥ marcado como outliers. En lugar de eliminarlos del subset (como se hizo en clase), se decidi√≥ mantenerlos en el dataset, ya que el an√°lisis posterior mostr√≥ que estos productos coincid√≠an con dos situaciones:\n",
    "\n",
    "- **Top ventas** ‚Üí productos de alta rotaci√≥n cuya exclusi√≥n hubiera distorsionado la demanda real.\n",
    "- **Picos aislados coherentes** ‚Üí ventas puntuales pero justificadas por campa√±as, estacionalidad o ventanas de grandes ventas.\n",
    "\n",
    "Durante la Fase 6, para garantizar que todos los productos participaran en el modelado por cl√∫ster, se cre√≥ la columna __cluster__.\n",
    "\n",
    "- En los productos no outliers (is_outlier = 0), cluster y __cluster__ son id√©nticos.\n",
    "- En los productos outliers (is_outlier = 1), se aplic√≥ un **criterio de fallback determinista**, asign√°ndolos al cl√∫ster mayoritario (cl√∫ster 1).\n",
    "\n",
    "**Limitaciones**\n",
    "\n",
    "- Este enfoque diluye en cierta medida la especificidad de los outliers.\n",
    "- Sin embargo, dado que en este caso **todos los outliers estaban justificados** (bien por ser top ventas, bien por picos coherentes con la √©poca), su integraci√≥n en el cl√∫ster mayoritario no compromete la validez del modelo.\n",
    "\n",
    "**Enfoque adoptado**\n",
    "\n",
    "- Se opta por mantener la asignaci√≥n al cl√∫ster mayoritario para no dejar productos fuera del pipeline.\n",
    "- Se documenta esta decisi√≥n como un compromiso entre simplicidad, cobertura y coherencia de negocio.\n",
    "- Como l√≠nea futura, se podr√≠a explorar una reasignaci√≥n basada en distancias a centroides u otras m√©tricas, pero no se considera necesaria en esta fase.\n",
    "\n",
    "\n",
    "**Posible l√≠nea futura: clustering espec√≠fico de outliers**\n",
    "\n",
    "En el presente proyecto los productos identificados como outliers fueron integrados en el cl√∫ster mayoritario con el objetivo de garantizar su cobertura en \n",
    "el modelado y evitar su eliminaci√≥n, dado que en su mayor√≠a correspond√≠an a top ventas o a picos de demanda coherentes con la estacionalidad.\n",
    "\n",
    "Como l√≠nea de trabajo futura, se podr√≠a plantear un clustering espec√≠fico sobre el conjunto de outliers. Esta estrategia permitir√≠a identificar subgrupos internos \n",
    "(por ejemplo, distinguir entre productos con alta rotaci√≥n recurrente frente a productos con picos estacionales aislados) y, en consecuencia, aplicar modelos diferenciados m√°s ajustados a cada comportamiento.\n",
    "\n",
    "No obstante, dado que el volumen de productos outliers es reducido respecto al total (alrededor de un 5‚Äì6 %) y que los modelos con variables ex√≥genas ya permiten explicar \n",
    "sus patrones de manera satisfactoria, se considera que esta extensi√≥n no es necesaria en la versi√≥n actual del modelo y se pospone como l√≠nea futura de refinamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8ea7f",
   "metadata": {},
   "source": [
    "## FASE 7: **Validaci√≥n y preparaci√≥n del dataset para el modelado**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba7ccc",
   "metadata": {},
   "source": [
    "En esta fase se lleva a cabo el √∫ltimo bloque de **preparaci√≥n de datos** antes del entrenamiento de los modelos.  \n",
    "El objetivo es garantizar que el dataset final cumple con todos los requisitos de **integridad, consistencia y trazabilidad**, de modo que pueda ser utilizado como entrada estable y homog√©nea en la fase de modelado.\n",
    "\n",
    "**Objetivos principales.**\n",
    "- Validar el dataset base (`subset_modelado.parquet`) para confirmar que no existen problemas estructurales (nulos, negativos, duplicados, incoherencias de cl√∫steres u outliers).  \n",
    "- Normalizar y depurar las columnas, renombrando y eliminando redundancias.  \n",
    "- Definir expl√≠citamente la variable objetivo (*target*) y las variables explicativas (*features*) disponibles para los modelos.  \n",
    "- Generar un dataset final consolidado (`dataset_modelado_ready.parquet`) que act√∫e como **input √∫nico y reproducible** para todos los experimentos de la fase de modelado.\n",
    "\n",
    "\n",
    "> üìå Con esta fase se cierra todo el bloque de preparaci√≥n, asegurando que los modelos de la Fase 8 se entrenar√°n sobre datos limpios, validados y coherentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e984ad",
   "metadata": {},
   "source": [
    "### **7.1. Validaci√≥n inicial del dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30e0a9",
   "metadata": {},
   "source": [
    "\n",
    "El primer paso antes de comenzar con el modelado consiste en realizar una **validaci√≥n exhaustiva del dataset de partida**.  \n",
    "El objetivo de este bloque es garantizar que los datos sobre los que se entrenar√°n los modelos son **consistentes, completos y utilizables**, evitando que errores estructurales condicionen los resultados posteriores.\n",
    "\n",
    "üéØ **Objetivo**\n",
    "- Comprobar que la **variable objetivo** (`demand_final_noised`) no presenta valores nulos ni negativos.\n",
    "- Verificar que las **fechas** cubren el rango esperado (2022‚Äì2024) y que no existen duplicados en la combinaci√≥n (`product_id`, `date`).\n",
    "- Identificar posibles problemas de cobertura temporal (fechas faltantes, series constantes, productos incompletos).\n",
    "- Validar que todos los **productos tienen un cl√∫ster asignado** y que la informaci√≥n de outliers est√° correctamente registrada.\n",
    "- Revisar de forma preliminar las **variables de precio y factores externos**.\n",
    "\n",
    "‚ùì **Por qu√© se realiza**\n",
    "Una validaci√≥n previa es esencial porque:\n",
    "- Asegura que los **modelos trabajen con datos coherentes** y sin inconsistencias.\n",
    "- Evita que los resultados del backtesting est√©n sesgados por errores de entrada.\n",
    "- Permite identificar productos o periodos problem√°ticos antes de invertir tiempo en el entrenamiento.\n",
    "\n",
    "üõ†Ô∏è **C√≥mo se lleva a cabo**\n",
    "La validaci√≥n se efect√∫a mediante un **script espec√≠fico** (`validacion_dataset_modelado.py`) que genera un reporte con:\n",
    "- Informaci√≥n general del dataset.\n",
    "- Estado de la variable objetivo.\n",
    "- Cobertura temporal por producto.\n",
    "- Comprobaciones sobre cl√∫steres y outliers.\n",
    "- Un **resumen tipo sem√°foro** (OK/NO-OK) de las validaciones cr√≠ticas.\n",
    "\n",
    "> De esta manera, cualquier problema estructural queda documentado y puede ser corregido antes de pasar a la fase de preparaci√≥n de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e815e",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **Script: `validacion_dataset_modelado.py`**\n",
    "\n",
    "üéØ **Objetivo.**  \n",
    "Automatizar la validaci√≥n del dataset de modelado, comprobando la integridad de la variable objetivo, la cobertura temporal, los cl√∫steres y la trazabilidad de los outliers. Este script act√∫a como herramienta de diagn√≥stico previa al modelado.\n",
    "\n",
    "‚û°Ô∏è **Entradas.**\n",
    "- `data/processed/subset_modelado.parquet` (dataset validado en Fases 1‚Äì6).\n",
    "\n",
    "‚¨ÖÔ∏è **Salidas.**\n",
    "- Reporte en consola con todos los resultados de validaci√≥n.  \n",
    "- (Opcional) Archivo TXT si se especifica `--report`.\n",
    "\n",
    "üîÅ **Flujo de trabajo.**\n",
    "1. **Carga del dataset** (Parquet).  \n",
    "2. **Chequeo de columnas y tipos** (`df.info()` capturado en buffer).  \n",
    "3. **Validaci√≥n de la variable objetivo**: nulos, negativos, estad√≠sticos b√°sicos.  \n",
    "4. **Cobertura temporal**: fechas m√≠nimas/m√°ximas globales y por producto; detecci√≥n de duplicados `product_id+date`; c√°lculo de completitud diaria.  \n",
    "5. **Series constantes**: identifica productos con demanda sin variaci√≥n.  \n",
    "6. **Precio y factores**: detecci√≥n de valores nulos/negativos en columnas relevantes (`precio_medio`, `price_factor_effective`).  \n",
    "7. **Validaci√≥n de cl√∫steres**: confirmaci√≥n de que todos los productos tienen cl√∫ster asignado; coherencia `cluster` vs `__cluster__` en productos no-outlier.  \n",
    "8. **Outliers**: verificaci√≥n de columnas relacionadas, recuento de productos marcados y n√∫mero de cl√∫steres asignados.  \n",
    "9. **Resumen ‚Äúsem√°foro‚Äù**: indicadores booleanos (`OK=True/False`) de las comprobaciones cr√≠ticas.\n",
    "\n",
    "ü™õ **Par√°metros modificables.**\n",
    "- Rutas de entrada y salida (`--in`, `--report`).\n",
    "- Nombre de la variable objetivo (`demand_final_noised` por defecto).\n",
    "\n",
    "üß© **Ejecuci√≥n.**\n",
    "- CLI:  \n",
    "  ```bash\n",
    "  python scripts/eda/validacion_dataset_modelado.py\n",
    "  python scripts/eda/validacion_dataset_modelado.py --report reports/validacion_dataset.txt\n",
    "\n",
    "- Notebook:\n",
    "\n",
    " `from scripts.eda.validacion_dataset_modelado import run_validation`\n",
    " \n",
    " `print(run_validation())`\n",
    "\n",
    "üìù **Notas.**\n",
    "- El script no modifica el dataset original.\n",
    "- Si se encuentra alg√∫n problema cr√≠tico (ej. nulos en target, fechas fuera de rango), debe ser corregido antes de continuar con el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f36272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 11:29:18,994 | INFO | notebook.validacion_dataset_modelado | Leyendo: C:\\Users\\crisr\\Desktop\\M√°ster Data Science & IA\\PROYECTO\\PFM2_Asistente_Compras_Inteligente\\data\\processed\\subset_modelado.parquet\n",
      "2025-09-08 11:29:19,657 | INFO | notebook.validacion_dataset_modelado | Validando‚Ä¶\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENCABEZADOS ===\n",
      "['precio_medio', 'product_id', 'demand_day', 'is_outlier', 'cluster', 'date', '__cluster__', '__product_id__', 'demand_multiplier', 'demand_day_priceadj', 'price_factor_effective', 'price_virtual', 'm_agosto_nonprice', 'm_competition', 'm_inflation', 'm_promo', 'm_seasonextra', 'm_segments', 'demand_final', 'factors_applied', 'demand_final_noised', 'demand_final_noiseds_adj', 'year', 'tipo_outlier_year', 'decision_outlier_year']\n",
      "\n",
      "=== INFO ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3941216 entries, 0 to 3941215\n",
      "Data columns (total 25 columns):\n",
      " #   Column                    Non-Null Count    Dtype         \n",
      "---  ------                    --------------    -----         \n",
      " 0   precio_medio              3941216 non-null  float64       \n",
      " 1   product_id                3941216 non-null  string        \n",
      " 2   demand_day                3941216 non-null  float64       \n",
      " 3   is_outlier                3941216 non-null  int64         \n",
      " 4   cluster                   3720920 non-null  float64       \n",
      " 5   date                      3941216 non-null  datetime64[ns]\n",
      " 6   __cluster__               3941216 non-null  int64         \n",
      " 7   __product_id__            3941216 non-null  int64         \n",
      " 8   demand_multiplier         3941216 non-null  float64       \n",
      " 9   demand_day_priceadj       3941216 non-null  float64       \n",
      " 10  price_factor_effective    3941216 non-null  float64       \n",
      " 11  price_virtual             3941216 non-null  float64       \n",
      " 12  m_agosto_nonprice         3941216 non-null  float64       \n",
      " 13  m_competition             3941216 non-null  float64       \n",
      " 14  m_inflation               3941216 non-null  float64       \n",
      " 15  m_promo                   3941216 non-null  float64       \n",
      " 16  m_seasonextra             3941216 non-null  float64       \n",
      " 17  m_segments                3941216 non-null  float64       \n",
      " 18  demand_final              3941216 non-null  float64       \n",
      " 19  factors_applied           3941216 non-null  object        \n",
      " 20  demand_final_noised       3941216 non-null  float64       \n",
      " 21  demand_final_noiseds_adj  3720920 non-null  float64       \n",
      " 22  year                      3941216 non-null  Int64         \n",
      " 23  tipo_outlier_year         3941216 non-null  object        \n",
      " 24  decision_outlier_year     3941216 non-null  object        \n",
      "dtypes: Int64(1), datetime64[ns](1), float64(16), int64(3), object(3), string(1)\n",
      "memory usage: 755.5+ MB\n",
      "\n",
      "=== TARGET (demand_final_noised) ===\n",
      "Nulos: 0\n",
      "Negativos: 0\n",
      "count    3.941216e+06\n",
      "mean     2.130598e+00\n",
      "std      1.001068e+00\n",
      "min      1.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      2.000000e+00\n",
      "75%      3.000000e+00\n",
      "max      1.500000e+01\n",
      "Name: demand_final_noised, dtype: float64\n",
      "\n",
      "=== COBERTURA GLOBAL DE FECHAS ===\n",
      "Min: 2022-01-01 00:00:00  |  Max: 2024-12-31 00:00:00\n",
      "\n",
      "Duplicados (product_id, date): 0\n",
      "Productos con fechas faltantes: 0\n",
      "Completitud media %: 100.0\n",
      "Productos con demanda constante (√∫nico valor): 265\n",
      "\n",
      "=== CHEQUEO precio_medio ===\n",
      "Nulos: 0 | Negativos: 0 | Min: 5.09 | Max: 99.99\n",
      "\n",
      "=== CHEQUEO price_factor_effective ===\n",
      "Nulos: 0 | Negativos: 0 | Min: 0.75 | Max: 1.0\n",
      "\n",
      "=== CL√öSTERES (__cluster__) ===\n",
      "Productos √∫nicos: 3596\n",
      "Productos con cluster: 3596\n",
      "Productos SIN cluster: 0\n",
      "Cluster y __cluster__ id√©nticos en NO-outliers: True\n",
      "\n",
      "=== COLUMNAS OUTLIERS ===\n",
      "['is_outlier', 'tipo_outlier_year', 'decision_outlier_year']\n",
      "Productos outlier: 201\n",
      "Clusters distintos en outliers: 1\n",
      "\n",
      "=== RESUMEN (OK=True) ===\n",
      "target_sin_nulos: True\n",
      "target_sin_negativos: True\n",
      "sin_duplicados_pid_fecha: True\n",
      "cluster_cubierto: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Script: validaci√≥n_dataset_modelado.py\n",
    "# Validaci√≥n inicial del dataset de modelado\n",
    "# Objetivo: foto r√°pida y completa de calidad de datos y trazabilidad de cl√∫ster/outliers\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import logging\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- Helper: encontrar ra√≠z del repo (carpeta que contenga data/processed) ----------\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    p = Path(start or Path.cwd()).resolve()\n",
    "    for parent in (p, *p.parents):\n",
    "        if (parent / \"data\" / \"processed\").exists():\n",
    "            return parent\n",
    "    return p  # fallback: cwd si no encuentra nada\n",
    "\n",
    "# ---------- Rutas por defecto (funciona en script y en notebook) ----------\n",
    "if \"__file__\" in globals():\n",
    "    _start = Path(__file__).resolve().parent\n",
    "    LOGGER_NAME = Path(__file__).stem\n",
    "else:\n",
    "    _start = Path.cwd()\n",
    "    LOGGER_NAME = \"notebook.validacion_dataset_modelado\"\n",
    "\n",
    "ROOT_DIR = find_repo_root(_start)\n",
    "PROCESSED_DIR = ROOT_DIR / \"data\" / \"processed\"\n",
    "\n",
    "# ---------- Logging ----------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    ")\n",
    "log = logging.getLogger(LOGGER_NAME)\n",
    "\n",
    "\n",
    "# ---------- N√∫cleo de validaci√≥n ----------\n",
    "def validate_dataset(df: pd.DataFrame, target: str = \"demand_final_noised\") -> str:\n",
    "    \"\"\"Devuelve un string con el reporte de validaci√≥n.\"\"\"\n",
    "    lines: list[str] = []\n",
    "\n",
    "    # 1) Columnas / tipos\n",
    "    lines.append(\"=== ENCABEZADOS ===\")\n",
    "    lines.append(str(list(df.columns)))\n",
    "\n",
    "    lines.append(\"\\n=== INFO ===\")\n",
    "    buf = io.StringIO()                       # <- buffer v√°lido para df.info()\n",
    "    df.info(buf=buf, show_counts=True)\n",
    "    lines.extend(buf.getvalue().splitlines())\n",
    "\n",
    "    # 2) Target\n",
    "    assert target in df.columns, f\"No existe la columna objetivo '{target}'\"\n",
    "    tgt = df[target]\n",
    "    lines.append(f\"\\n=== TARGET ({target}) ===\")\n",
    "    lines.append(f\"Nulos: {int(tgt.isna().sum())}\")\n",
    "    lines.append(f\"Negativos: {int((tgt < 0).sum())}\")\n",
    "    lines.append(str(tgt.describe()))\n",
    "\n",
    "    # 3) Fechas y cobertura\n",
    "    assert \"date\" in df.columns, \"Falta columna 'date'\"\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    lines.append(\"\\n=== COBERTURA GLOBAL DE FECHAS ===\")\n",
    "    lines.append(f\"Min: {df['date'].min()}  |  Max: {df['date'].max()}\")\n",
    "\n",
    "    # Duplicados product_id+date\n",
    "    dups = int(df.duplicated([\"product_id\", \"date\"]).sum())\n",
    "    lines.append(f\"\\nDuplicados (product_id, date): {dups}\")\n",
    "\n",
    "    # Continuidad diaria por producto\n",
    "    span = df.groupby(\"product_id\")[\"date\"].agg([\"min\", \"max\", \"count\"])\n",
    "    span[\"dias_esperados\"] = (span[\"max\"] - span[\"min\"]).dt.days + 1\n",
    "    span[\"completitud_%\"] = (span[\"count\"] / span[\"dias_esperados\"] * 100).round(2)\n",
    "    faltantes = int((span[\"completitud_%\"] < 100).sum())\n",
    "    lines.append(f\"Productos con fechas faltantes: {faltantes}\")\n",
    "    lines.append(f\"Completitud media %: {span['completitud_%'].mean().round(2)}\")\n",
    "\n",
    "    # Series constantes\n",
    "    var0 = int((df.groupby(\"product_id\")[target].nunique() == 1).sum())\n",
    "    lines.append(f\"Productos con demanda constante (√∫nico valor): {var0}\")\n",
    "\n",
    "    # 4) Precio (si existe)\n",
    "    for col in [\"precio_medio\", \"price_factor_effective\"]:\n",
    "        if col in df.columns:\n",
    "            lines.append(f\"\\n=== CHEQUEO {col} ===\")\n",
    "            lines.append(\n",
    "                f\"Nulos: {int(df[col].isna().sum())} | Negativos: {int((df[col] < 0).sum())} \"\n",
    "                f\"| Min: {df[col].min()} | Max: {df[col].max()}\"\n",
    "            )\n",
    "\n",
    "    # 5) Cl√∫steres\n",
    "    cluster_col = \"__cluster__\" if \"__cluster__\" in df.columns else (\"cluster\" if \"cluster\" in df.columns else None)\n",
    "    assert cluster_col is not None, \"No hay columna de cluster ni __cluster__\"\n",
    "    lines.append(f\"\\n=== CL√öSTERES ({cluster_col}) ===\")\n",
    "    lines.append(f\"Productos √∫nicos: {df['product_id'].nunique()}\")\n",
    "    lines.append(f\"Productos con cluster: {df.loc[df[cluster_col].notna(), 'product_id'].nunique()}\")\n",
    "    lines.append(f\"Productos SIN cluster: {df.loc[df[cluster_col].isna(), 'product_id'].nunique()}\")\n",
    "\n",
    "    # Coherencia en NO-outliers\n",
    "    if {\"cluster\", \"__cluster__\", \"is_outlier\"}.issubset(df.columns):\n",
    "        no_out = df[\"is_outlier\"].eq(0)\n",
    "        iguales = (df.loc[no_out, \"cluster\"].fillna(-1).astype(int)\n",
    "                   == df.loc[no_out, \"__cluster__\"].astype(int)).all()\n",
    "        lines.append(f\"Cluster y __cluster__ id√©nticos en NO-outliers: {bool(iguales)}\")\n",
    "\n",
    "    # 6) Outliers\n",
    "    outlier_cols = [c for c in df.columns if \"outlier\" in c.lower()]\n",
    "    lines.append(\"\\n=== COLUMNAS OUTLIERS ===\")\n",
    "    lines.append(str(outlier_cols))\n",
    "    if \"is_outlier\" in df.columns:\n",
    "        n_out = int(df.query(\"is_outlier == 1\")[\"product_id\"].nunique())\n",
    "        lines.append(f\"Productos outlier: {n_out}\")\n",
    "        asign = df.loc[df[\"is_outlier\"] == 1, [\"product_id\", cluster_col]].drop_duplicates()\n",
    "        lines.append(f\"Clusters distintos en outliers: {asign[cluster_col].nunique()}\")\n",
    "\n",
    "    # 7) Resumen sem√°foro\n",
    "    checks = {\n",
    "        \"target_sin_nulos\": int(tgt.isna().sum()) == 0,\n",
    "        \"target_sin_negativos\": int((tgt < 0).sum()) == 0,\n",
    "        \"sin_duplicados_pid_fecha\": dups == 0,\n",
    "        \"cluster_cubierto\": df.loc[df[cluster_col].isna(), \"product_id\"].nunique() == 0,\n",
    "    }\n",
    "    lines.append(\"\\n=== RESUMEN (OK=True) ===\")\n",
    "    for k, v in checks.items():\n",
    "        lines.append(f\"{k}: {bool(v)}\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ---------- CLI (ignora flags extra de Jupyter) ----------\n",
    "def _parse_args() -> argparse.Namespace:\n",
    "    p = argparse.ArgumentParser(description=\"Validaci√≥n inicial del dataset de modelado (no escribe por defecto).\")\n",
    "    p.add_argument(\"--in\", dest=\"inp\", type=str, default=str(PROCESSED_DIR / \"subset_modelado.parquet\"),\n",
    "                   help=\"Ruta de entrada (PARQUET).\")\n",
    "    p.add_argument(\"--report\", dest=\"report\", type=str, default=\"\",\n",
    "                   help=\"Ruta TXT para volcar el reporte (opcional).\")\n",
    "    args, _ = p.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "# ---------- Atajo para usar desde notebook ----------\n",
    "def run_validation(inp: str | Path = None, report: str | Path = None) -> str:\n",
    "    inp_path = Path(inp) if inp else (PROCESSED_DIR / \"subset_modelado.parquet\")\n",
    "    log.info(\"Leyendo: %s\", inp_path)\n",
    "    df = pd.read_parquet(inp_path)\n",
    "    log.info(\"Validando‚Ä¶\")\n",
    "    rep = validate_dataset(df)\n",
    "    if report:\n",
    "        report = Path(report)\n",
    "        report.parent.mkdir(parents=True, exist_ok=True)\n",
    "        report.write_text(rep, encoding=\"utf-8\")\n",
    "        log.info(\"Reporte guardado en: %s\", report)\n",
    "    return rep\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    args = _parse_args()\n",
    "    txt = run_validation(args.inp, args.report)\n",
    "    print(txt)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3c84e",
   "metadata": {},
   "source": [
    "üìä **Resultados de la validaci√≥n inicial del dataset**\n",
    "\n",
    "La validaci√≥n aplicada sobre `subset_modelado.parquet` confirma que el dataset de partida es **consistente y apto para el modelado**.  \n",
    "\n",
    "**Principales resultados:**\n",
    "- ‚úîÔ∏è **Estructura completa**: se detectaron 25 columnas, incluyendo demanda, producto, cl√∫steres, precios y factores externos.  \n",
    "- ‚úîÔ∏è **Variable objetivo (`demand_final_noised`)**: sin valores nulos ni negativos.  \n",
    "- ‚úîÔ∏è **Integridad temporal**: fechas cubren el rango esperado (2022‚Äì2024), sin duplicados en la combinaci√≥n (`product_id`, `date`).  \n",
    "- ‚úîÔ∏è **Cobertura de cl√∫steres**: todos los productos tienen un cl√∫ster asignado.  \n",
    "- ‚úîÔ∏è **Factores de precio y externos**: columnas presentes y sin anomal√≠as graves.  \n",
    "\n",
    "**Implicaciones para el modelado:**\n",
    "- El dataset puede utilizarse directamente en la preparaci√≥n (fase 7.2) sin necesidad de limpieza adicional.  \n",
    "- La ausencia de nulos/duplicados evita sesgos en el backtesting y facilita la comparabilidad de m√©tricas.  \n",
    "- La cobertura de cl√∫steres garantiza que se pueda aplicar el enfoque de modelado **por cl√∫ster**, manteniendo consistencia metodol√≥gica.  \n",
    "\n",
    "> En conclusi√≥n, el dataset validado ofrece una **base s√≥lida y coherente** para iniciar la fase de modelado, reduciendo riesgos de errores estructurales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c73871",
   "metadata": {},
   "source": [
    "Adem√°s de la validaci√≥n principal, se cuenta con un **script espec√≠fico** (`check_outliers_clusters.py`)para auditar la coherencia de los *outliers* respecto a los cl√∫steres.\n",
    "\n",
    "**Objetivo.**  \n",
    "Comprobar que:\n",
    "- Los productos no marcados como *outliers* mantienen coherencia entre `cluster` y `__cluster__`.\n",
    "- Los productos marcados como *outliers* tienen un cl√∫ster asignado y se registra correctamente su distribuci√≥n.\n",
    "\n",
    "**Entradas.**\n",
    "- `data/processed/subset_modelado.parquet`\n",
    "\n",
    "**Salidas.**\n",
    "- Reporte en consola con:\n",
    "  - Distribuci√≥n de cl√∫steres.\n",
    "  - Coherencia `cluster` vs `__cluster__` en productos no-outlier.\n",
    "  - Resumen de productos outlier y cl√∫steres asignados.\n",
    "\n",
    "**Uso.**\n",
    "- CLI:\n",
    "  ```bash\n",
    "  python scripts/eda/check_outliers_clusters.py\n",
    "  python scripts/eda/check_outliers_clusters.py --report reports/outliers/summary_outliers_clusters.txt\n",
    "\n",
    "**Notas.**\n",
    "\n",
    "- Este script se considera una herramienta auxiliar para auditor√≠as puntuales.\n",
    "- Su ejecuci√≥n no es obligatoria en el pipeline, ya que la validaci√≥n principal (validacion_dataset_modelado.py) garantiza la integridad global.\n",
    "- Se recomienda utilizarlo si se desea revisar en detalle la trazabilidad de los outliers o documentar auditor√≠as espec√≠ficas.\n",
    "\n",
    "\n",
    "üìä **Resultados de la comprobaci√≥n auxiliar de outliers y cl√∫steres**\n",
    "Se ejecut√≥ el script `check_outliers_clusters.py` para verificar la coherencia de los *outliers* en relaci√≥n con los cl√∫steres.  \n",
    "\n",
    "**Principales hallazgos:**\n",
    "- ‚úîÔ∏è **Distribuci√≥n de cl√∫steres**: se identificaron 4 valores (0‚Äì3), con asignaci√≥n equilibrada y sin anomal√≠as.\n",
    "- ‚úîÔ∏è **No-outliers**: las columnas `cluster` y `__cluster__` son id√©nticas para todos los productos ‚Üí confirmada la coherencia.\n",
    "- ‚úîÔ∏è **Outliers**: 201 productos fueron marcados como outliers, y todos ellos fueron asignados de forma determinista al cl√∫ster mayoritario (`__cluster__ = 1`).\n",
    "\n",
    "**Implicaciones:**\n",
    "- La asignaci√≥n determinista a cl√∫ster 1 asegura que ning√∫n producto queda fuera del pipeline de modelado.\n",
    "- La validaci√≥n confirma que no existen inconsistencias entre `cluster` y `__cluster__` en los productos no-outlier.\n",
    "- La estrategia adoptada (incluir outliers como parte del cl√∫ster mayoritario) se mantiene v√°lida y no compromete la coherencia metodol√≥gica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342d6f7",
   "metadata": {},
   "source": [
    "### **7.2. Preparaci√≥n de los datos para el modelado.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fdc3a6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Tras validar la integridad del dataset en el apartado 7.1, el siguiente paso consiste en **normalizar y depurar la estructura de datos** para que pueda ser utilizada directamente en el entrenamiento de los modelos.\n",
    "\n",
    "üéØ **Objetivo**.\n",
    "- Unificar nombres de columnas clave.\n",
    "- Eliminar duplicados y redundancias.\n",
    "- Definir expl√≠citamente el target y las features.\n",
    "- Generar un dataset limpio y homog√©neo que sirva como input est√°ndar para todos los modelos.\n",
    "\n",
    "üîÅ **Pasos realizados**.\n",
    "1. **Renombrado de columnas:**\n",
    "   - `__cluster__` ‚Üí `cluster_id`  \n",
    "   - `demand_final_noised` ‚Üí `sales_quantity`  \n",
    "\n",
    "2. **Eliminaci√≥n de duplicados:**\n",
    "   - Se descartan `cluster` y `__product_id__`, ya que eran copias redundantes de `__cluster__` y `product_id`.\n",
    "\n",
    "3. **Selecci√≥n de variables explicativas (features):**\n",
    "   - Precio: `precio_medio`, `price_virtual`, `price_factor_effective`, `demand_day_priceadj`.  \n",
    "   - Factores externos: `m_agosto_nonprice`, `m_competition`, `m_inflation`, `m_promo`, entre otros.  \n",
    "   - Outliers y trazabilidad: `is_outlier`, `tipo_outlier_year`, `decision_outlier_year`.  \n",
    "   - Identificadores y fecha: `product_id`, `cluster_id`, `date`.\n",
    "\n",
    "4. **Control de consistencia:**\n",
    "   - Verificaci√≥n de ausencia de duplicados en (`product_id`, `date`).  \n",
    "   - Confirmaci√≥n de que no existen valores nulos en la variable objetivo (`sales_quantity`).\n",
    "\n",
    "5. **Exportaci√≥n:**\n",
    "   - Se genera el dataset final `data/processed/dataset_modelado_ready.parquet`, que ser√° utilizado de manera uniforme en todos los experimentos de modelado.\n",
    "\n",
    "üß™ **Resultado**.\n",
    "El dataset preparado garantiza una **base coherente, sin ambig√ºedades ni redundancias**, y con una estructura estable que facilita:\n",
    "- La aplicaci√≥n consistente de modelos estad√≠sticos y de machine learning.  \n",
    "- La reproducibilidad de los experimentos (todos los modelos parten de la misma entrada).  \n",
    "- La trazabilidad de resultados (columnas de target y features claramente identificadas).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110f34b",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **Script: `preparacion_dataset_modelado.py`**\n",
    "\n",
    "üéØ **Objetivo.**  \n",
    "Normalizar y depurar el dataset de partida para que quede listo para el modelado, eliminando redundancias y asegurando que la estructura sea homog√©nea y estable.\n",
    "\n",
    "‚û°Ô∏è **Entradas.**\n",
    "- `data/processed/subset_modelado.parquet`\n",
    "\n",
    "‚¨ÖÔ∏è **Salidas.**\n",
    "- `data/processed/dataset_modelado_ready.parquet` (dataset final listo para modelado).\n",
    "\n",
    "üîÅ **Flujo de trabajo.**\n",
    "1. **Renombrado de columnas clave**  \n",
    "   - `__cluster__` ‚Üí `cluster_id`  \n",
    "   - `demand_final_noised` ‚Üí `sales_quantity`  \n",
    "\n",
    "2. **Eliminaci√≥n de columnas redundantes**  \n",
    "   - `cluster` (duplicado de `__cluster__`),  \n",
    "   - `__product_id__` (duplicado de `product_id`),  \n",
    "   - `demand_final_noiseds_adj` (columna auxiliar no utilizada).  \n",
    "\n",
    "3. **Normalizaci√≥n de tipos**  \n",
    "   - `date` ‚Üí formato datetime.  \n",
    "   - `product_id` ‚Üí string.  \n",
    "   - `cluster_id` ‚Üí entero (`int` o `Int64` si hay nulos).  \n",
    "\n",
    "4. **Control de duplicados y nulos**  \n",
    "   - Eliminaci√≥n de duplicados por (`product_id`, `date`).  \n",
    "   - Filtrado de posibles nulos en `sales_quantity`.  \n",
    "\n",
    "5. **Selecci√≥n de variables finales**  \n",
    "   - Identificadores y target: `product_id`, `date`, `cluster_id`, `sales_quantity`.  \n",
    "   - Features de precio, factores externos y trazabilidad (`precio_medio`, `price_virtual`, `m_promo`, `is_outlier`, etc.).  \n",
    "   - Ordenaci√≥n por (`product_id`, `date`).  \n",
    "\n",
    "6. **Exportaci√≥n**  \n",
    "   - Se guarda el dataset consolidado en `data/processed/dataset_modelado_ready.parquet`.  \n",
    "\n",
    "üìù **Notas.**\n",
    "- Este dataset es la **base de referencia para todos los modelos** de la Fase 7, evitando revalidaciones y asegurando consistencia.  \n",
    "- La eliminaci√≥n de redundancias y la normalizaci√≥n de tipos garantizan la trazabilidad y reproducibilidad de los resultados.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33ec834a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 12:29:42,828 | INFO | notebook.preparacion_dataset_modelado | Leyendo: C:\\Users\\crisr\\Desktop\\M√°ster Data Science & IA\\PROYECTO\\PFM2_Asistente_Compras_Inteligente\\data\\processed\\subset_modelado.parquet\n",
      "2025-09-08 12:29:43,464 | INFO | notebook.preparacion_dataset_modelado | Preparando dataset‚Ä¶\n",
      "2025-09-08 12:29:43,837 | INFO | notebook.preparacion_dataset_modelado | Eliminando columnas redundantes: ['cluster', '__product_id__', 'demand_final_noiseds_adj']\n",
      "2025-09-08 12:29:46,970 | INFO | notebook.preparacion_dataset_modelado | Guardado dataset listo para modelado en: C:\\Users\\crisr\\Desktop\\M√°ster Data Science & IA\\PROYECTO\\PFM2_Asistente_Compras_Inteligente\\data\\processed\\dataset_modelado_ready.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Script: preparacion_dataset_modelado.py\n",
    "# =============================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Helper: localizar ra√≠z del repo (busca data/processed hacia arriba)\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    p = Path(start or Path.cwd()).resolve()\n",
    "    for parent in (p, *p.parents):\n",
    "        if (parent / \"data\" / \"processed\").exists():\n",
    "            return parent\n",
    "    return p  # fallback\n",
    "\n",
    "# ---------- Entorno (sirve para script y notebook)\n",
    "if \"__file__\" in globals():\n",
    "    _start = Path(__file__).resolve().parent\n",
    "    LOGGER_NAME = Path(__file__).stem\n",
    "else:\n",
    "    _start = Path.cwd()\n",
    "    LOGGER_NAME = \"notebook.preparacion_dataset_modelado\"\n",
    "\n",
    "ROOT_DIR = find_repo_root(_start)\n",
    "PROCESSED_DIR = ROOT_DIR / \"data\" / \"processed\"\n",
    "\n",
    "# ---------- Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    ")\n",
    "log = logging.getLogger(LOGGER_NAME)\n",
    "\n",
    "# ---------- Config ‚Äúsuave‚Äù: columnas a eliminar/renombrar/usar si existen\n",
    "RENAME_MAP = {\n",
    "    \"__cluster__\": \"cluster_id\",\n",
    "    \"demand_final_noised\": \"sales_quantity\",\n",
    "}\n",
    "DROP_CANDIDATES = [\n",
    "    \"cluster\",               # duplicado: nos quedamos con __cluster__ -> cluster_id\n",
    "    \"__product_id__\",        # duplicado de product_id\n",
    "    \"demand_final_noiseds_adj\",  # columna auxiliar que no aporta\n",
    "]\n",
    "# Features recomendadas (se usar√° la intersecci√≥n para evitar KeyError)\n",
    "FEATURES_RECOMENDADAS = [\n",
    "    # ids & fecha (estos los forzamos aparte)\n",
    "    # target -> sales_quantity (tras renombrado)\n",
    "    \"precio_medio\",\n",
    "    \"price_virtual\",\n",
    "    \"price_factor_effective\",\n",
    "    \"demand_day_priceadj\",\n",
    "    # factores externos\n",
    "    \"m_agosto_nonprice\",\n",
    "    \"m_competition\",\n",
    "    \"m_inflation\",\n",
    "    \"m_promo\",\n",
    "    # trazabilidad/outliers (opcionales, seg√∫n uso como ex√≥genas)\n",
    "    \"is_outlier\",\n",
    "    \"tipo_outlier_year\",\n",
    "    \"decision_outlier_year\",\n",
    "]\n",
    "\n",
    "# ---------- N√∫cleo ------------------------------------------------------------\n",
    "def prepare_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Aplica la preparaci√≥n para modelado y devuelve el DataFrame listo.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) Renombrados (solo si existen)\n",
    "    cols_a_renombrar = {c: n for c, n in RENAME_MAP.items() if c in df.columns}\n",
    "    df = df.rename(columns=cols_a_renombrar)\n",
    "\n",
    "    # Validaciones m√≠nimas\n",
    "    required = {\"product_id\", \"date\", \"cluster_id\", \"sales_quantity\"}\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Faltan columnas requeridas tras renombrado: {missing}\")\n",
    "\n",
    "    # 2) Eliminar columnas redundantes si existen\n",
    "    to_drop = [c for c in DROP_CANDIDATES if c in df.columns]\n",
    "    if to_drop:\n",
    "        log.info(\"Eliminando columnas redundantes: %s\", to_drop)\n",
    "        df = df.drop(columns=to_drop)\n",
    "\n",
    "    # 3) Normalizar tipos\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"product_id\"] = df[\"product_id\"].astype(str)\n",
    "    # cluster_id como int (permitiendo nulos si los hubiera por seguridad)\n",
    "    if df[\"cluster_id\"].isna().any():\n",
    "        df[\"cluster_id\"] = df[\"cluster_id\"].astype(\"Int64\")\n",
    "    else:\n",
    "        df[\"cluster_id\"] = df[\"cluster_id\"].astype(int)\n",
    "\n",
    "    # 4) Control de duplicados por (product_id, date)\n",
    "    dups = df.duplicated([\"product_id\", \"date\"])\n",
    "    n_dup = int(dups.sum())\n",
    "    if n_dup > 0:\n",
    "        log.warning(\"Se detectaron %s duplicados (product_id, date). Se conservar√° el primero.\", n_dup)\n",
    "        df = df.loc[~dups].copy()\n",
    "\n",
    "    # 5) Verificaci√≥n de nulos en target\n",
    "    n_null_target = int(df[\"sales_quantity\"].isna().sum())\n",
    "    if n_null_target > 0:\n",
    "        log.warning(\"Se encontraron %s nulos en sales_quantity. Filtrando filas nulas.\", n_null_target)\n",
    "        df = df.loc[df[\"sales_quantity\"].notna()].copy()\n",
    "\n",
    "    # 6) Selecci√≥n de columnas finales (intersecci√≥n segura)\n",
    "    keep_base = [\"product_id\", \"date\", \"cluster_id\", \"sales_quantity\"]\n",
    "    keep_feats = [c for c in FEATURES_RECOMENDADAS if c in df.columns]\n",
    "    cols_finales = keep_base + keep_feats\n",
    "    df = df[cols_finales].sort_values([\"product_id\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- CLI ---------------------------------------------------------------\n",
    "def _parse_args() -> argparse.Namespace:\n",
    "    p = argparse.ArgumentParser(description=\"Preparaci√≥n del dataset para modelado.\")\n",
    "    p.add_argument(\"--in\",  dest=\"inp\",  type=str, default=str(PROCESSED_DIR / \"subset_modelado.parquet\"),\n",
    "                   help=\"Ruta de entrada (PARQUET).\")\n",
    "    p.add_argument(\"--out\", dest=\"outp\", type=str, default=str(PROCESSED_DIR / \"dataset_modelado_ready.parquet\"),\n",
    "                   help=\"Ruta de salida (PARQUET).\")\n",
    "    # Ignora flags de Jupyter si corre dentro de notebook\n",
    "    args, _ = p.parse_known_args()\n",
    "    return args\n",
    "\n",
    "def run_prep(inp: str | Path = None, outp: str | Path = None) -> str:\n",
    "    \"\"\"Atajo para usar desde notebook o como funci√≥n.\"\"\"\n",
    "    inp_path = Path(inp) if inp else (PROCESSED_DIR / \"subset_modelado.parquet\")\n",
    "    out_path = Path(outp) if outp else (PROCESSED_DIR / \"dataset_modelado_ready.parquet\")\n",
    "\n",
    "    log.info(\"Leyendo: %s\", inp_path)\n",
    "    df = pd.read_parquet(inp_path)\n",
    "\n",
    "    log.info(\"Preparando dataset‚Ä¶\")\n",
    "    df_ready = prepare_dataset(df)\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_ready.to_parquet(out_path, index=False)\n",
    "    log.info(\"Guardado dataset listo para modelado en: %s\", out_path)\n",
    "\n",
    "    return str(out_path)\n",
    "\n",
    "def main() -> None:\n",
    "    args = _parse_args()\n",
    "    run_prep(args.inp, args.outp)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ddaef",
   "metadata": {},
   "source": [
    "‚úÖ **Verificaci√≥n post-transformaci√≥n del dataset listo para modelado.**\n",
    "\n",
    "Tras la preparaci√≥n del dataset (`dataset_modelado_ready.parquet`), se realiza una verificaci√≥n ligera para asegurar que la transformaci√≥n **no ha introducido errores** y que la estructura final es apta para los modelos.\n",
    "\n",
    "**Qu√© se comprueba:**\n",
    "- **Cobertura temporal:** las fechas abarcan el rango esperado (2022-01-01 ‚Üí 2024-12-31).\n",
    "- **Target (`sales_quantity`):** sin valores **nulos** ni **negativos**.  \n",
    "  > No se validan los **ceros** porque son coherentes con d√≠as sin ventas.\n",
    "- **Identificador (`product_id`):** sin nulos, sin valores ‚Äú0‚Äù ni cadenas vac√≠as.\n",
    "- **Duplicados:** no existen duplicados en la combinaci√≥n (`product_id`, `date`).\n",
    "- **Cl√∫ster (`cluster_id`):** sin valores nulos y con valores dentro del rango esperado.\n",
    "\n",
    "**Por qu√© es necesaria esta verificaci√≥n:**\n",
    "- Cada transformaci√≥n (renombrados, drops, normalizaci√≥n) puede introducir errores de forma accidental.\n",
    "- Esta comprobaci√≥n act√∫a como **‚Äúpost-check‚Äù** del bloque 7.2 y da garant√≠as de que el dataset preparado mantiene la **integridad y consistencia** exigidas por el pipeline de modelado.\n",
    "\n",
    "> Esta verificaci√≥n es **operativa** y se mantiene en el **notebook** (no forma parte del pipeline en scripts) para agilizar el trabajo exploratorio y la defensa del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57382c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cobertura temporal ===\n",
      "Fecha m√≠nima: 2022-01-01 00:00:00\n",
      "Fecha m√°xima: 2024-12-31 00:00:00\n",
      "Cobertura dentro del rango esperado: True\n",
      "\n",
      "=== sales_quantity (target) ===\n",
      "Nulos: 0\n",
      "Negativos: 0\n",
      "Target OK (sin nulos ni negativos): True\n",
      "\n",
      "=== product_id ===\n",
      "Nulos: 0\n",
      "Valores '0': 0\n",
      "Vac√≠os (''): 0\n",
      "√önicos: 3596\n",
      "product_id OK (no nulos/0/vac√≠os): True\n",
      "\n",
      "=== Duplicados (product_id, date) ===\n",
      "Duplicados: 0\n",
      "Sin duplicados pid+date: True\n",
      "\n",
      "=== cluster_id ===\n",
      "Nulos: 0\n",
      "Valores √∫nicos: [0, 1, 2, 3]\n",
      "cluster_id OK (sin nulos): True\n",
      "\n",
      "=== Resumen (OK=True) ===\n",
      "cobertura_temporal_ok: True\n",
      "target_ok: True\n",
      "product_id_ok: True\n",
      "sin_duplicados_pid_date: True\n",
      "cluster_ok: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Script: preparacion_dataset_modelado.py\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Config ===\n",
    "PATH_READY = Path(r\"C:\\Users\\crisr\\Desktop\\M√°ster Data Science & IA\\PROYECTO\\PFM2_Asistente_Compras_Inteligente\\data\\processed\\dataset_modelado_ready.parquet\")\n",
    "FECHA_MIN_ESPERADA = pd.Timestamp(\"2022-01-01\")\n",
    "FECHA_MAX_ESPERADA = pd.Timestamp(\"2024-12-31\")\n",
    "\n",
    "# === Carga ===\n",
    "df = pd.read_parquet(PATH_READY)\n",
    "\n",
    "# Asegurar tipos\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"product_id\"] = df[\"product_id\"].astype(str)\n",
    "\n",
    "print(\"=== Cobertura temporal ===\")\n",
    "print(\"Fecha m√≠nima:\", df[\"date\"].min())\n",
    "print(\"Fecha m√°xima:\", df[\"date\"].max())\n",
    "cobertura_ok = (df[\"date\"].min() <= FECHA_MIN_ESPERADA) and (df[\"date\"].max() >= FECHA_MAX_ESPERADA)\n",
    "print(\"Cobertura dentro del rango esperado:\", cobertura_ok)\n",
    "\n",
    "print(\"\\n=== sales_quantity (target) ===\")\n",
    "print(\"Nulos:\", int(df[\"sales_quantity\"].isna().sum()))\n",
    "print(\"Negativos:\", int((df[\"sales_quantity\"] < 0).sum()))\n",
    "target_ok = (df[\"sales_quantity\"].isna().sum() == 0) and ((df[\"sales_quantity\"] < 0).sum() == 0)\n",
    "print(\"Target OK (sin nulos ni negativos):\", target_ok)\n",
    "\n",
    "print(\"\\n=== product_id ===\")\n",
    "print(\"Nulos:\", int(df[\"product_id\"].isna().sum()))\n",
    "print(\"Valores '0':\", int((df[\"product_id\"] == \"0\").sum()))\n",
    "print(\"Vac√≠os (''):\", int((df[\"product_id\"].str.len() == 0).sum()))\n",
    "print(\"√önicos:\", df[\"product_id\"].nunique())\n",
    "pid_ok = (df[\"product_id\"].isna().sum() == 0) and ((df[\"product_id\"] == \"0\").sum() == 0) and ((df[\"product_id\"].str.len() == 0).sum() == 0)\n",
    "print(\"product_id OK (no nulos/0/vac√≠os):\", pid_ok)\n",
    "\n",
    "print(\"\\n=== Duplicados (product_id, date) ===\")\n",
    "dup_count = int(df.duplicated([\"product_id\", \"date\"]).sum())\n",
    "print(\"Duplicados:\", dup_count)\n",
    "dups_ok = dup_count == 0\n",
    "print(\"Sin duplicados pid+date:\", dups_ok)\n",
    "\n",
    "print(\"\\n=== cluster_id ===\")\n",
    "print(\"Nulos:\", int(df[\"cluster_id\"].isna().sum()))\n",
    "vals = sorted(pd.Series(df[\"cluster_id\"].dropna().unique()).tolist())\n",
    "print(\"Valores √∫nicos:\", vals)\n",
    "cluster_ok = df[\"cluster_id\"].isna().sum() == 0\n",
    "print(\"cluster_id OK (sin nulos):\", cluster_ok)\n",
    "\n",
    "print(\"\\n=== Resumen (OK=True) ===\")\n",
    "checks = {\n",
    "    \"cobertura_temporal_ok\": cobertura_ok,\n",
    "    \"target_ok\": target_ok,\n",
    "    \"product_id_ok\": pid_ok,\n",
    "    \"sin_duplicados_pid_date\": dups_ok,\n",
    "    \"cluster_ok\": cluster_ok,\n",
    "}\n",
    "for k, v in checks.items():\n",
    "    print(f\"{k}: {bool(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f11301",
   "metadata": {},
   "source": [
    "üìä **Resultados de la verificaci√≥n post-transformaci√≥n**.\n",
    "\n",
    "La verificaci√≥n realizada sobre el dataset `dataset_modelado_ready.parquet` confirma que la transformaci√≥n no introdujo errores y que la estructura final es **coherente y apta para el modelado**.\n",
    "\n",
    "**Hallazgos principales:**\n",
    "- ‚úîÔ∏è **Cobertura temporal completa:** fechas desde 2022-01-01 hasta 2024-12-31.  \n",
    "- ‚úîÔ∏è **Target (`sales_quantity`):** sin nulos ni valores negativos. Los ceros se mantienen como representaci√≥n v√°lida de d√≠as sin ventas.  \n",
    "- ‚úîÔ∏è **Product_ID:** sin nulos, sin valores inv√°lidos (0 o cadenas vac√≠as). Se identifican 3.596 productos √∫nicos.  \n",
    "- ‚úîÔ∏è **Duplicados:** no existen duplicados en la combinaci√≥n (`product_id`, `date`).  \n",
    "- ‚úîÔ∏è **Cluster_ID:** todos los productos tienen cl√∫ster asignado (0‚Äì3), sin nulos ni valores fuera de rango.  \n",
    "\n",
    "> **Conclusi√≥n:**  \n",
    "El dataset preparado conserva la integridad y consistencia requeridas.  \n",
    "Esto asegura que el archivo `dataset_modelado_ready.parquet` puede utilizarse como **input √∫nico y estable** en todos los experimentos de la Fase 7, garantizando trazabilidad, reproducibilidad y ausencia de sesgos estructurales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5fdf1c",
   "metadata": {},
   "source": [
    "### **7.3. Target y features disponibles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19542e18",
   "metadata": {},
   "source": [
    "En este subapartado se define de manera expl√≠cita cu√°l es la variable objetivo (*target*) que se busca predecir y qu√© variables explicativas (*features*) quedan disponibles tras la preparaci√≥n del dataset.\n",
    "\n",
    "üéØ **Target**.\n",
    "- **Variable:** `sales_quantity`  \n",
    "- **Origen:** procede de `demand_final_noised`, validada en la Fase 7.1 y renombrada en la Fase 7.2.  \n",
    "- **Justificaci√≥n:** representa la demanda diaria final de cada producto, incorporando estacionalidad, efectos de precio y factores externos, adem√°s de un ruido controlado para asegurar realismo.  \n",
    "- **Integridad:** validada previamente ‚Üí sin valores nulos ni negativos.  \n",
    "- **Uso:** ser√° la variable dependiente en todos los modelos de predicci√≥n de demanda.\n",
    "\n",
    "üö¶ **Features disponibles**.\n",
    "Tras la preparaci√≥n del dataset (`dataset_modelado_ready.parquet`), las variables independientes que pueden usarse como explicativas son:\n",
    "\n",
    "- **Identificadores y estructura temporal**\n",
    "  - `product_id` (identificador √∫nico del producto)  \n",
    "  - `date` (fecha ‚Üí √≠ndice temporal para los modelos)  \n",
    "  - `cluster_id` (agrupaci√≥n de productos para modelado por cl√∫ster)\n",
    "\n",
    "- **Precio y derivados**\n",
    "  - `precio_medio`  \n",
    "  - `price_virtual`  \n",
    "  - `price_factor_effective`  \n",
    "  - `demand_day_priceadj`\n",
    "\n",
    "- **Factores externos**\n",
    "  - `m_agosto_nonprice`  \n",
    "  - `m_competition`  \n",
    "  - `m_inflation`  \n",
    "  - `m_promo`  \n",
    "  - (otros marcadores estacionales si se conservan en el dataset)\n",
    "\n",
    "- **Variables de outliers y trazabilidad (opcionales)**\n",
    "  - `is_outlier`  \n",
    "  - `tipo_outlier_year`  \n",
    "  - `decision_outlier_year`\n",
    "\n",
    "üìå **Implicaci√≥n metodol√≥gica**\n",
    "- Los modelos temporales cl√°sicos (SARIMAX, Holt-Winters) trabajar√°n principalmente con el target y, en algunos casos, con ex√≥genas seleccionadas (precio, promociones, etc.).  \n",
    "- Los modelos de regresi√≥n y *machine learning* (Ridge, Random Forest) podr√°n explotar un conjunto m√°s amplio de features.  \n",
    "- Este listado **no implica una selecci√≥n final de variables**; √∫nicamente define el universo de columnas disponibles y aptas para ser utilizadas en la Fase 8 (modelado).  \n",
    "\n",
    "> En **conclusi√≥n**, el dataset `dataset_modelado_ready.parquet` queda establecido como la base oficial del modelado:  \n",
    "> - Target √∫nico: `sales_quantity`  \n",
    "> - Features disponibles: las listadas en este subapartado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9065998e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3f9e0",
   "metadata": {},
   "source": [
    "## FASE 8: **Modelado de la demanda**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e2b61",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## 8.1 Introducci√≥n\n",
    "- Objetivo: predecir la demanda diaria por `product_id` para el horizonte 2025.  \n",
    "- Punto de partida: dataset validado y preparado en la **Fase 7**.  \n",
    "  - Dataset base: `data/processed/dataset_modelado_ready.parquet`.  \n",
    "  - Target definido: `sales_quantity`.  \n",
    "  - Features disponibles: precio, factores externos, variables de outliers y trazabilidad, adem√°s de los identificadores y fecha.  \n",
    "- Enfoque metodol√≥gico: modelado **por cl√∫ster** para capturar patrones de productos con comportamientos similares.\n",
    "\n",
    "\n",
    "\n",
    "## 8.2 Preparaci√≥n del dataset para entrenamiento\n",
    "- Carga del dataset `dataset_modelado_ready.parquet`.  \n",
    "- Divisi√≥n temporal de los datos:\n",
    "  - Train: 2022‚Äì2023  \n",
    "  - Validaci√≥n: 2024  \n",
    "  - Test: 2025 (enero‚Äìagosto)  \n",
    "- Configuraci√≥n de esquema de **backtesting (walk-forward)** para asegurar que la validaci√≥n respeta la naturaleza temporal.  \n",
    "- M√©tricas de evaluaci√≥n que se utilizar√°n:  \n",
    "  - MAE (error absoluto medio).  \n",
    "  - WAPE (Weighted Absolute Percentage Error).  \n",
    "  - sMAPE (Symmetric MAPE).  \n",
    "\n",
    "\n",
    "\n",
    "## 8.3 Baselines\n",
    "- **Seasonal Naive** ‚Üí repetir la demanda del mismo d√≠a del a√±o anterior.  \n",
    "- **Holt-Winters (ETS)** ‚Üí modelo de suavizado exponencial con componentes estacionales.  \n",
    "\n",
    "Objetivo: establecer benchmarks m√≠nimos contra los que comparar los modelos m√°s complejos.\n",
    "\n",
    "\n",
    "## 8.4 Modelos cl√°sicos de series temporales\n",
    "- **SARIMAX** (con ex√≥genas):  \n",
    "  - Usar precios y factores externos como regresores.  \n",
    "  - Comparar por cl√∫ster el ajuste frente a los baselines.  \n",
    "\n",
    "\n",
    "\n",
    "## 8.5 Modelos de regresi√≥n y machine learning\n",
    "- **Ridge Regression** ‚Üí modelo lineal regularizado con variables ex√≥genas.  \n",
    "- **Random Forest Regressor** ‚Üí modelo de ML no lineal que puede explotar interacciones entre features.  \n",
    "- Nota: estos modelos requieren preparaci√≥n de features (dummies de calendario, normalizaci√≥n opcional).\n",
    "\n",
    "\n",
    "\n",
    "## 8.6 Backtesting y comparaci√≥n de resultados\n",
    "- Validaci√≥n walk-forward por cl√∫ster:  \n",
    "  - Ventanas de entrenamiento: 2022‚Äì2023.  \n",
    "  - Ventanas de validaci√≥n: 2024 (ej. bloques de 28 d√≠as).  \n",
    "- Comparaci√≥n de m√©tricas (MAE, WAPE, sMAPE).  \n",
    "- Selecci√≥n del modelo ganador por cl√∫ster.  \n",
    "\n",
    "\n",
    "\n",
    "## 8.7 Predicciones finales\n",
    "- Entrenamiento final con datos 2022‚Äì2024.  \n",
    "- Predicci√≥n de la demanda diaria de 2025 (enero‚Äìagosto) por producto y cl√∫ster.  \n",
    "- Exportaci√≥n de resultados a:  \n",
    "  - `processed/predicciones_2025.parquet`  \n",
    "\n",
    "\n",
    "\n",
    "## 8.8 Conclusiones y l√≠neas futuras\n",
    "- Evaluaci√≥n de qu√© modelos ofrecen mejor rendimiento seg√∫n el cl√∫ster.  \n",
    "- An√°lisis de las limitaciones detectadas.  \n",
    "- L√≠neas de mejora:\n",
    "  - Incorporar modelos m√°s avanzados (XGBoost, Prophet, LSTM).  \n",
    "  - Refinar la simulaci√≥n de ex√≥genas.  \n",
    "  - Ajustar manualmente previsiones en casos de eventos extraordinarios.  \n",
    "\n",
    "\n",
    "\n",
    "# üîé Recordatorio de la Fase 7 (resumen)\n",
    "- Dataset validado con `validacion_dataset_modelado.py`.  \n",
    "- Outliers auditados con `check_outliers_clusters.py`.  \n",
    "- Dataset preparado y normalizado con `preparacion_dataset_modelado.py`.  \n",
    "- Verificaci√≥n post-transformaci√≥n en notebook (cobertura temporal, integridad de target, duplicados, product_id, cl√∫steres).  \n",
    "- Definici√≥n de target y features disponibles (`sales_quantity` y variables explicativas).  \n",
    "\n",
    "El resultado de la Fase 7 es el archivo **`dataset_modelado_ready.parquet`**, que ser√° el input √∫nico y estable para todos los experimentos de modelado en esta Fase 8.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c63f4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En esta fase se aborda el **modelado de la demanda diaria** por producto (`product_id`) con horizonte en el a√±o 2025.  \n",
    "El objetivo es construir y comparar distintos modelos predictivos que permitan anticipar la **variable objetivo `sales_quantity`**, incorporando tanto patrones hist√≥ricos como factores explicativos adicionales.\n",
    "\n",
    "üü¢ **Punto de partida**  \n",
    "El proceso parte del dataset validado y preparado en la **Fase 7**, garantizando su coherencia y trazabilidad.  \n",
    "- **Input**: `data/processed/dataset_modelado_ready.parquet`.  \n",
    "- **Target definido**: `sales_quantity`.  \n",
    "- **Features disponibles**:  \n",
    "  - **Precio** (impacto de la elasticidad y promociones).  \n",
    "  - **Factores externos** (eventos, calendario, estacionalidad).  \n",
    "  - **Variables de outliers** (identificaci√≥n y trazabilidad de anomal√≠as).  \n",
    "  - **Identificadores y metadata**: `product_id`, `cluster`, fecha, etc. \n",
    "\n",
    "\n",
    "üóÇÔ∏è **Justificaci√≥n metodol√≥gica.**\n",
    "\n",
    "Existen dos enfoques habituales en problemas de predicci√≥n de demanda:\n",
    "1. **Modelado individual por producto**  \n",
    "   - Permite capturar la din√°mica espec√≠fica de cada `product_id`.  \n",
    "   - Inconveniente: elevado coste computacional y alta varianza en productos con poca demanda o hist√≥rico reducido.  \n",
    "\n",
    "2. **Modelado agregado por cl√∫ster**  \n",
    "   - Los productos se agrupan seg√∫n similitud de patrones de consumo, lo que genera un **mayor volumen de datos representativos por grupo**.  \n",
    "   - Facilita la detecci√≥n de regularidades compartidas y reduce el riesgo de sobreajuste en productos con baja venta o alta estacionalidad.  \n",
    "   - Es m√°s escalable y alineado con el enfoque de negocio: gestionar previsiones de stock a nivel de tipolog√≠as de productos.  \n",
    "\n",
    "Dado el contexto de este proyecto, se opta por un **enfoque por cl√∫ster**, aprovechando la segmentaci√≥n previa para construir modelos que capturen los patrones comunes y permitan comparaciones m√°s estables.\n",
    "\n",
    "\n",
    "\n",
    "üö¶ **Resultado esperado.**  \n",
    "El resultado de esta fase ser√° un conjunto de modelos entrenados y evaluados **por cl√∫ster**, con capacidad para:\n",
    "- Predecir la demanda diaria de 2025 (enero‚Äìagosto).  \n",
    "- Comparar el rendimiento de distintos enfoques (baselines, modelos cl√°sicos de series temporales y modelos de machine learning).  \n",
    "- Seleccionar el modelo √≥ptimo para cada cl√∫ster en base a m√©tricas de error (MAE, WAPE, sMAPE).  \n",
    "\n",
    "Estas predicciones se exportar√°n en un archivo √∫nico que servir√° como entrada para la etapa final de an√°lisis y optimizaci√≥n del stock.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117544e",
   "metadata": {},
   "source": [
    "### **8.1. Preparaci√≥n de data set para entrenamiento.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2869c0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "El primer paso en el proceso de modelado consiste en preparar el dataset para garantizar que los experimentos sean reproducibles, comparables y respeten la naturaleza temporal de los datos.\n",
    "\n",
    "\n",
    "üîã **Carga del dataset.**\n",
    "El punto de partida es el archivo validado en la Fase 7:  \n",
    "- **Input**: `data/processed/dataset_modelado_ready.parquet`  \n",
    "- **Caracter√≠sticas**: contiene las variables necesarias para el entrenamiento, incluyendo el target `sales_quantity`, las features ex√≥genas (precio, factores externos, calendario, outliers) y los identificadores (`product_id`, `cluster`, fecha).\n",
    "\n",
    "\n",
    "üóìÔ∏è **Divisi√≥n temporal de los datos.**\n",
    "Se define una separaci√≥n estrictamente temporal, evitando fugas de informaci√≥n entre conjuntos:\n",
    "- **Entrenamiento (Train)**: a√±os 2022‚Äì2023.  \n",
    "- **Validaci√≥n (Validation)**: a√±o 2024, usado para selecci√≥n de hiperpar√°metros y comparaci√≥n de modelos.  \n",
    "- **Test (Hold-out Test)**: horizonte 2025 (enero‚Äìdiciembre), reservado para la evaluaci√≥n final.  \n",
    "\n",
    "> Esta divisi√≥n garantiza que el modelo se entrene √∫nicamente con informaci√≥n pasada y sea evaluado con datos futuros.\n",
    "\n",
    "\n",
    "\n",
    "‚è≥ **Esquema de validaci√≥n temporal.**\n",
    "Se aplicar√° un enfoque de **backtesting walk-forward**, donde se generan ventanas de entrenamiento y validaci√≥n que avanzan en el tiempo.  \n",
    "- Ventanas de entrenamiento: 2022‚Äì2023.  \n",
    "- Ventanas de validaci√≥n: bloques sucesivos de 2024 (ej. tramos de 28 d√≠as).  \n",
    "\n",
    "> Este procedimiento permite evaluar la robustez de los modelos frente a distintos periodos del a√±o y refuerza la validez de las m√©tricas obtenidas.\n",
    "\n",
    "\n",
    "\n",
    "üìê **M√©tricas de evaluaci√≥n.**\n",
    "Para comparar el rendimiento de los distintos modelos se emplear√°n m√©tricas espec√≠ficas de predicci√≥n de series temporales:  \n",
    "- **MAE (Mean Absolute Error)** ‚Üí mide el error medio absoluto en las predicciones.  \n",
    "- **WAPE (Weighted Absolute Percentage Error)** ‚Üí pondera el error respecto al volumen total de demanda, √∫til para comparar productos con diferentes escalas.  \n",
    "- **sMAPE (Symmetric Mean Absolute Percentage Error)** ‚Üí m√©trica porcentual sim√©trica que facilita la comparaci√≥n entre modelos.  \n",
    "\n",
    "> El uso de varias m√©tricas asegura una evaluaci√≥n integral del rendimiento y evita sesgos derivados de productos con mayor volumen de ventas.\n",
    "\n",
    "\n",
    "\n",
    "‚úÖ **Resultado esperado.**\n",
    "Un dataset correctamente dividido en conjuntos de **entrenamiento, validaci√≥n y test**, junto con un esquema de backtesting definido, que permita evaluar de forma justa y consistente los modelos a desarrollar en los apartados posteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d7b063",
   "metadata": {},
   "source": [
    "### **8.2. Baselines.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71e0b5",
   "metadata": {},
   "source": [
    "Antes de implementar modelos m√°s sofisticados, es necesario establecer **modelos de referencia o benchmarks** que act√∫en como punto de comparaci√≥n.  \n",
    "Estos baselines permiten evaluar si los modelos avanzados (series temporales cl√°sicas o machine learning) realmente aportan valor adicional frente a m√©todos sencillos y consolidados.\n",
    "\n",
    "\n",
    "‚ùì **¬øQu√© se va a hacer en este subapartado?**\n",
    "1. **Definir y aplicar dos m√©todos baseline** para la predicci√≥n de demanda diaria:  \n",
    "   - **Seasonal Naive**: la demanda de un d√≠a se estima igual a la del mismo d√≠a del a√±o anterior.  \n",
    "   - **Holt-Winters (ETS)**: un modelo de suavizado exponencial que incorpora nivel, tendencia y estacionalidad.  \n",
    "2. **Entrenar y evaluar estos m√©todos** sobre el conjunto de validaci√≥n (2024) y posteriormente en el test (2025).  \n",
    "3. **Calcular m√©tricas de error (MAE, WAPE, sMAPE)** para establecer un rendimiento m√≠nimo que los modelos avanzados deber√°n superar.\n",
    "\n",
    "\n",
    "\n",
    "üìö **Justificaci√≥n de las t√©cnicas seleccionadas**.\n",
    "- **Seasonal Naive**:  \n",
    "  - Es el baseline m√°s simple y robusto en problemas con fuerte estacionalidad, como la demanda en ecommerce.  \n",
    "  - Proporciona un ‚Äúsuelo‚Äù de rendimiento: cualquier modelo avanzado deber√≠a mejorar sus resultados.  \n",
    "\n",
    "- **Holt-Winters (ETS)**:  \n",
    "  - Incorpora no solo la estacionalidad, sino tambi√©n tendencias crecientes o decrecientes en las series.  \n",
    "  - Es flexible y ampliamente utilizado en predicci√≥n de demanda en retail.  \n",
    "  - Sirve como benchmark ‚Äúfuerte‚Äù frente al cual validar si los modelos cl√°sicos (SARIMAX) o de machine learning realmente son competitivos.  \n",
    "\n",
    "\n",
    "üö¶ **Resultado esperado**.\n",
    "\n",
    "Al finalizar este subapartado contaremos con un conjunto de m√©tricas asociadas a los **baselines** que funcionar√°n como **criterio m√≠nimo de comparaci√≥n**.  \n",
    "De esta forma, podremos garantizar que cualquier modelo posterior (series temporales avanzadas o ML) no solo es m√°s complejo, sino tambi√©n **m√°s preciso y √∫til para el negocio**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b853c7",
   "metadata": {},
   "source": [
    "#### **8.2.1. Enfoque por cl√∫ster.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d836671e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Un aspecto clave en este proyecto es que el **modelado de la demanda se realizar√° siempre por cl√∫ster**, y no a nivel individual por producto ni de manera agregada global.  \n",
    "Por este motivo, los **baselines tambi√©n se calcular√°n a nivel de cl√∫ster**, asegurando as√≠ la coherencia metodol√≥gica y la trazabilidad del pipeline.\n",
    "\n",
    "\n",
    "\n",
    "‚ùì **¬øPor qu√© no a nivel global?**\n",
    "- Un baseline global sobreestima la calidad del modelo, ya que oculta los errores que se producen en ciertos grupos de productos.  \n",
    "- Aunque podr√≠a ser √∫til como visi√≥n agregada, no resulta representativo para la comparaci√≥n real con los modelos avanzados que se entrenar√°n por cl√∫ster.  \n",
    "\n",
    "‚ùì **¬øPor qu√© no a nivel de producto?**\n",
    "- El c√°lculo individual de baselines por producto es m√°s preciso, pero genera un alto coste computacional en cat√°logos con cientos o miles de referencias.  \n",
    "- Adem√°s, muchos productos con baja demanda no disponen de suficiente hist√≥rico para que el baseline sea robusto.  \n",
    "\n",
    "‚ùì **¬øPor qu√© s√≠ a nivel de cl√∫ster?**\n",
    "- Permite capturar patrones estacionales y de tendencia caracter√≠sticos de cada grupo.  \n",
    "- Aporta un volumen de datos suficiente para construir baselines representativos y estables.  \n",
    "- Escalable: el n√∫mero de cl√∫steres es reducido y manejable frente al n√∫mero de productos.  \n",
    "- Coherente: el rendimiento de los modelos avanzados (SARIMAX, Ridge, Random Forest) se comparar√° con el baseline correspondiente al mismo cl√∫ster.\n",
    "\n",
    "\n",
    "\n",
    "üö¶ **Resultado esperado**.\n",
    "Para cada cl√∫ster se obtendr√°n m√©tricas de error (MAE, WAPE, sMAPE) asociadas a los baselines **Seasonal Naive** y **Holt-Winters**, que funcionar√°n como **puntos de referencia m√≠nimos** que deber√°n superar los modelos posteriores.  \n",
    "De esta manera, cada cl√∫ster contar√° con un benchmark propio, lo que asegura que las comparaciones sean justas y alineadas con la l√≥gica del negocio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08293c61",
   "metadata": {},
   "source": [
    "#### **8.2.2. Seasonal Naive.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d7367",
   "metadata": {},
   "source": [
    "\n",
    "El m√©todo **Seasonal Naive** es uno de los baselines m√°s utilizados en problemas de predicci√≥n de series temporales.  \n",
    "Se basa en una regla extremadamente simple:  \n",
    "> La demanda de un d√≠a se predice como igual a la demanda observada en el mismo d√≠a del a√±o anterior.\n",
    "\n",
    "\n",
    "‚úèÔ∏è **Justificaci√≥n de uso**.\n",
    "- Es un modelo de referencia **robusto y competitivo** en entornos con marcada estacionalidad, como el ecommerce y el retail.  \n",
    "- Proporciona un **piso m√≠nimo de rendimiento**: cualquier modelo avanzado deber√≠a mejorar, como m√≠nimo, este resultado.  \n",
    "- Su simplicidad permite una r√°pida implementaci√≥n y comprensi√≥n, lo que lo convierte en un **benchmark universal en forecasting**.\n",
    "\n",
    "\n",
    "\n",
    "üõ†Ô∏è **Aplicaci√≥n en este proyecto**.\n",
    "El enfoque se aplicar√° **por cl√∫ster**, manteniendo la coherencia metodol√≥gica establecida:  \n",
    "- **Entrenamiento**: no requiere ajuste de par√°metros, ya que solo replica el valor observado en el a√±o anterior.  \n",
    "- **Validaci√≥n (2024)**:  \n",
    "  - Se utiliza la demanda diaria de 2023 como predictor de la demanda de 2024.  \n",
    "  - Se calculan m√©tricas de error (MAE, WAPE, sMAPE) por cl√∫ster.  \n",
    "- **Test (2025)**:  \n",
    "  - Se utiliza la demanda diaria de 2024 como predictor de la demanda de 2025.  \n",
    "  - En este caso **no se dispone de valores reales (`y_true`)**, por lo que √∫nicamente se generan predicciones.  \n",
    "  - Las m√©tricas de test solo podr√°n calcularse una vez que se disponga de la serie observada.\n",
    "\n",
    "\n",
    "\n",
    "üö¶ **Resultado esperado**.\n",
    "\n",
    "Se obtendr√°n m√©tricas de error por cl√∫ster que representar√°n el rendimiento m√≠nimo aceptable.  \n",
    "\n",
    "> El **Seasonal Naive** servir√° como baseline simple y dif√≠cil de batir en contextos altamente estacionales, marcando el umbral que deber√°n superar tanto los modelos cl√°sicos de series temporales como los de machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255b6d3",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **Script: `seasonal_naive.py`**\n",
    "\n",
    "Este script implementa el baseline **Seasonal Naive** para estimar la demanda diaria por **cl√∫ster**.  \n",
    "Sirve como **benchmark m√≠nimo** frente al cual comparar modelos m√°s complejos.\n",
    "\n",
    "\n",
    "\n",
    "‚ùì**Qu√© hace**\n",
    "1) Lee el dataset preparado de modelado (`data/processed/dataset_modelado_ready.parquet`).  \n",
    "2) Verifica columnas m√≠nimas: `date` (datetime), `sales_quantity` (num√©rica) y `cluster_id`.  \n",
    "3) **Agrega a nivel (date, cluster_id)** sumando la demanda de todos los productos del cl√∫ster para evitar joins explosivos.  \n",
    "4) Genera predicciones **por cl√∫ster** usando la regla:  \n",
    "   > demanda(d√≠a **t**, a√±o **Y**) = demanda(mismo **MM-DD**, a√±o **Y-1**).  \n",
    "5) Calcula m√©tricas en **validaci√≥n (2024)**: `MAE`, `WAPE`, `sMAPE` por cl√∫ster y global.  \n",
    "6) Produce predicciones de **test (2025)**:  \n",
    "   - Si hay `y_true`, calcula m√©tricas.  \n",
    "   - Si **no** hay `y_true`, solo exporta predicciones y **omite** m√©tricas de test (comportamiento esperado).  \n",
    "7) Gestiona el **29 de febrero**: si el a√±o destino no es bisiesto, lo elimina; si lo es y faltan valores, interpola con 28-feb/01-mar.\n",
    "\n",
    "\n",
    "üõ†Ô∏è **C√≥mo lo hace (paso a paso)**\n",
    "1. **Carga y validaci√≥n**  \n",
    "   - Convierte `date` a `datetime` si hace falta.  \n",
    "   - Acepta alias de cl√∫ster (`cluster`, `cluster_name`, etc.) si no encuentra `cluster_id`.  \n",
    "2. **Agregado cluster-d√≠a**  \n",
    "   - `groupby([date, cluster_id]).sum('sales_quantity')`.  \n",
    "3. **Predicci√≥n Seasonal Naive**  \n",
    "   - Crea un mapa `(cluster_id, MM-DD) ‚Üí valor a√±o anterior`.  \n",
    "   - Une este mapa con el a√±o objetivo para obtener `y_pred`.  \n",
    "4. **M√©tricas**  \n",
    "   - En validaci√≥n (2024) compara `y_pred` vs `y_true`: `MAE`, `WAPE`, `sMAPE` por cl√∫ster y **__GLOBAL__**.  \n",
    "   - En test (2025), solo si hay `y_true`.  \n",
    "5. **Exportaci√≥n (si se ejecuta como script)**  \n",
    "   - Predicciones:  \n",
    "     - `data/processed/preds/baselines/seasonal_naive/preds_val.parquet`  \n",
    "     - `data/processed/preds/baselines/seasonal_naive/preds_test.parquet`  \n",
    "   - M√©tricas:  \n",
    "     - `reports/baselines/seasonal_naive/metrics_validation.csv`  \n",
    "     - `reports/baselines/seasonal_naive/metrics_test.csv` (solo si hay `y_true`).\n",
    "\n",
    "\n",
    "\n",
    "üß©Ô∏è **Par√°metros clave (CLI / notebook)**\n",
    "- `--input` ‚Üí ruta al parquet de entrada (por defecto: `data/processed/dataset_modelado_ready.parquet`).  \n",
    "- `--date-col` (`date`), `--target-col` (`sales_quantity`), `--cluster-col` (`cluster_id`).  \n",
    "- `--train-years \"2022,2023\"` ¬∑ `--val-year 2024` ¬∑ `--test-year 2025`.  \n",
    "- `--leap-fill {interp,drop}` ‚Üí tratamiento del 29-feb.  \n",
    "- `--allow-missing-test` ‚Üí permite generar test sin m√©tricas cuando no existe `y_true`.\n",
    "\n",
    "\n",
    "\n",
    "‚û°Ô∏è **Entradas**\n",
    "- `data/processed/dataset_modelado_ready.parquet` con, al menos:  \n",
    "  `date`, `sales_quantity`, `cluster_id` (o alias admitidos).\n",
    "\n",
    "‚¨ÖÔ∏è **Salidas**\n",
    "- Predicciones y m√©tricas en las rutas indicadas arriba (o **solo en memoria** si se usa la versi√≥n de notebook sin guardado).\n",
    "\n",
    "\n",
    "‚úÖ **Resultados esperados**\n",
    "- **Validaci√≥n (2024)**: m√©tricas por cl√∫ster y global (MAE, WAPE, sMAPE) que act√∫an como **benchmark**.  \n",
    "- **Test (2025)**: predicciones por cl√∫ster; si no hay verdad terreno, **no** se generan m√©tricas (queda registrado en logs).  \n",
    "- Un baseline **robusto** y **trazable** que fija el **umbral m√≠nimo** que deben superar SARIMAX, Holt-Winters y modelos de ML.\n",
    "\n",
    "\n",
    "\n",
    "üìù **Notas**\n",
    "- El enfoque es **por cl√∫ster** para mantener la coherencia metodol√≥gica del proyecto.  \n",
    "- El **MAE** puede ser alto en cl√∫steres con gran volumen; prioriza **WAPE/sMAPE** para comparaciones justas.  \n",
    "- Los logs informan de a√±os detectados, tama√±o del agregado y rutas de exportaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc59b511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 20:18:13,263 | INFO | root | Leyendo dataset: C:\\Users\\crisr\\Desktop\\M√°ster Data Science & IA\\PROYECTO\\PFM2_Asistente_Compras_Inteligente\\data\\processed\\dataset_modelado_ready.parquet\n",
      "2025-09-08 20:18:13,758 | INFO | root | A√±os presentes en el dataset: [2022, 2023, 2024]\n",
      "2025-09-08 20:18:13,905 | INFO | root | Agregado cluster-d√≠a en 0.15s (rows=4,384, clusters=4)\n",
      "2025-09-08 20:18:13,925 | INFO | root | SN predict 2024: agregado + mapeo en 0.02s (rows=1,464, clusters=4)\n",
      "2025-09-08 20:18:13,935 | WARNING | root | Predicciones de test generadas SIN y_true. M√©tricas de test se omiten.\n",
      "2025-09-08 20:18:13,941 | INFO | root | SAVE_OUTPUTS=False ‚Üí No se guardan ficheros en disco.\n",
      "2025-09-08 20:18:13,942 | INFO | root | OK Seasonal-Naive. Tiempo total: 0.68s\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================\n",
    "# Script: seasonal_naive.py\n",
    "# ==================================================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import logging, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------- Configuraci√≥n m√≠nima ---------------------------------\n",
    "SAVE_OUTPUTS = False  # pon True si quieres que escriba los mismos ficheros que el script\n",
    "\n",
    "# Si sabes la ruta absoluta del parquet, puedes fijarla aqu√≠:\n",
    "ABS_INPUT = r\"C:\\Users\\crisr\\Desktop\\M√°ster Data Science & IA\\PROYECTO\\PFM2_Asistente_Compras_Inteligente\\data\\processed\\dataset_modelado_ready.parquet\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "# ---------------------------- Utilidades de rutas ----------------------------------\n",
    "def _guess_root_from_cwd() -> Path:\n",
    "    cwd = Path.cwd().resolve()\n",
    "    for p in [cwd, *cwd.parents]:\n",
    "        if (p / \"data\" / \"processed\").exists():\n",
    "            return p\n",
    "    return cwd\n",
    "\n",
    "ROOT_DIR      = _guess_root_from_cwd()\n",
    "DATA_DIR      = ROOT_DIR / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "REPORTS_DIR   = ROOT_DIR / \"reports\"\n",
    "OUTPUTS_DIR   = PROCESSED_DIR / \"preds\" / \"baselines\" / \"seasonal_naive\"\n",
    "DEFAULT_INPUT = (PROCESSED_DIR / \"dataset_modelado_ready.parquet\").resolve()\n",
    "\n",
    "# ---------------------------- M√©tricas y helpers -----------------------------------\n",
    "def ensure_dirs():\n",
    "    if SAVE_OUTPUTS:\n",
    "        (REPORTS_DIR / \"baselines\" / \"seasonal_naive\").mkdir(parents=True, exist_ok=True)\n",
    "        OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def check_columns(df: pd.DataFrame, date_col: str, target_col: str, cluster_col: str):\n",
    "    missing = [c for c in [date_col, target_col, cluster_col] if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Faltan columnas obligatorias: {missing}\")\n",
    "    if not np.issubdtype(df[date_col].dtype, np.datetime64):\n",
    "        raise TypeError(f\"La columna '{date_col}' debe ser datetime64. Tipado actual: {df[date_col].dtype}\")\n",
    "\n",
    "def add_month_day(df: pd.DataFrame, date_col: str) -> pd.DataFrame:\n",
    "    return df.assign(_mmdd=df[date_col].dt.strftime(\"%m-%d\"))\n",
    "\n",
    "def smape(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-8) -> float:\n",
    "    num = np.abs(y_true - y_pred)\n",
    "    den = (np.abs(y_true) + np.abs(y_pred)).clip(min=eps)\n",
    "    return np.mean(2.0 * num / den)\n",
    "\n",
    "def wape(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-8) -> float:\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.clip(np.sum(np.abs(y_true)), eps, None)\n",
    "\n",
    "def mae(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def augment_prev_with_feb29(prev_map: pd.DataFrame, target_col: str, cluster_col: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for cl, g in prev_map.groupby(cluster_col, sort=False):\n",
    "        if not (g[\"_mmdd\"] == \"02-29\").any():\n",
    "            v28 = g.loc[g[\"_mmdd\"] == \"02-28\", target_col].mean()\n",
    "            v01 = g.loc[g[\"_mmdd\"] == \"03-01\", target_col].mean()\n",
    "            if pd.notna(v28) and pd.notna(v01):\n",
    "                rows.append({cluster_col: cl, \"_mmdd\": \"02-29\", target_col: 0.5 * (v28 + v01)})\n",
    "            elif pd.notna(v28):\n",
    "                rows.append({cluster_col: cl, \"_mmdd\": \"02-29\", target_col: float(v28)})\n",
    "            elif pd.notna(v01):\n",
    "                rows.append({cluster_col: cl, \"_mmdd\": \"02-29\", target_col: float(v01)})\n",
    "    if rows:\n",
    "        prev_map = pd.concat([prev_map, pd.DataFrame(rows)], ignore_index=True)\n",
    "    return prev_map\n",
    "\n",
    "def aggregate_cluster_daily(df: pd.DataFrame, date_col: str, cluster_col: str, target_col: str) -> pd.DataFrame:\n",
    "    g = (\n",
    "        df[[date_col, cluster_col, target_col]]\n",
    "        .groupby([date_col, cluster_col], as_index=False, sort=False)[target_col]\n",
    "        .sum()\n",
    "    )\n",
    "    if g[cluster_col].dtype == \"object\":\n",
    "        g[cluster_col] = g[cluster_col].astype(\"category\")\n",
    "    return g\n",
    "\n",
    "def build_prev_map(prev_df: pd.DataFrame, date_col: str, cluster_col: str, target_col: str,\n",
    "                   ensure_feb29: bool) -> pd.DataFrame:\n",
    "    tmp = add_month_day(prev_df, date_col)[[cluster_col, \"_mmdd\", target_col]].copy()\n",
    "    tmp = tmp.groupby([cluster_col, \"_mmdd\"], as_index=False, sort=False)[target_col].mean()\n",
    "    if ensure_feb29:\n",
    "        tmp = augment_prev_with_feb29(tmp, target_col=target_col, cluster_col=cluster_col)\n",
    "    return tmp.rename(columns={target_col: \"y_prev\"})\n",
    "\n",
    "# ---------------------------- Baseline (id√©ntico) ----------------------------------\n",
    "def seasonal_naive_predict_cluster_level(\n",
    "    agg_df: pd.DataFrame, year_target: int, date_col: str, target_col: str,\n",
    "    cluster_col: str, leap_fill: str = \"interp\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Predicciones para year_target cuando S√ç hay y_true (validaci√≥n/test con verdad).\"\"\"\n",
    "    t0 = time.time()\n",
    "    prev_year = year_target - 1\n",
    "    is_target_leap = pd.Timestamp(year=year_target, month=12, day=31).is_leap_year\n",
    "\n",
    "    df_prev = agg_df[agg_df[date_col].dt.year == prev_year].copy()\n",
    "    df_tgt  = agg_df[agg_df[date_col].dt.year == year_target].copy()\n",
    "\n",
    "    prev_map = build_prev_map(\n",
    "        prev_df=df_prev, date_col=date_col, cluster_col=cluster_col, target_col=target_col,\n",
    "        ensure_feb29=(is_target_leap and leap_fill == \"interp\"),\n",
    "    )\n",
    "\n",
    "    df_tgt = add_month_day(df_tgt, date_col)\n",
    "    merged = (\n",
    "        df_tgt[[date_col, cluster_col, \"_mmdd\", target_col]]\n",
    "        .merge(prev_map, on=[cluster_col, \"_mmdd\"], how=\"left\")\n",
    "        .rename(columns={target_col: \"y_true\"})\n",
    "    )\n",
    "    merged[\"y_pred\"] = merged[\"y_prev\"]\n",
    "    merged = merged.drop(columns=[\"_mmdd\", \"y_prev\"], errors=\"ignore\").rename(columns={date_col: \"date\"})\n",
    "    merged[\"split_year\"] = year_target\n",
    "    merged = merged[[\"date\", cluster_col, \"y_true\", \"y_pred\", \"split_year\"]].sort_values([\"date\", cluster_col])\n",
    "\n",
    "    logging.info(f\"SN predict {year_target}: agregado + mapeo en {time.time()-t0:.2f}s \"\n",
    "                 f\"(rows={len(merged):,}, clusters={merged[cluster_col].nunique()})\")\n",
    "    return merged\n",
    "\n",
    "def seasonal_naive_forecast_without_truth_cluster_level(\n",
    "    agg_df: pd.DataFrame, year_target: int, date_col: str, target_col: str, cluster_col: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Predicciones de year_target SIN y_true a partir del a√±o anterior, a nivel cl√∫ster-d√≠a.\"\"\"\n",
    "    prev_year = year_target - 1\n",
    "    df_prev = agg_df[agg_df[date_col].dt.year == prev_year].copy()\n",
    "    if df_prev.empty:\n",
    "        raise ValueError(f\"No hay datos del a√±o anterior ({prev_year}) para predecir {year_target}.\")\n",
    "\n",
    "    tmp = df_prev[[date_col, cluster_col, target_col]].copy()\n",
    "    tmp[\"_mmdd\"] = tmp[date_col].dt.strftime(\"%m-%d\")\n",
    "\n",
    "    is_target_leap = pd.Timestamp(year=year_target, month=12, day=31).is_leap_year\n",
    "    if not is_target_leap:\n",
    "        tmp = tmp.loc[tmp[\"_mmdd\"] != \"02-29\"].copy()\n",
    "\n",
    "    tmp[\"date_target\"] = pd.to_datetime(str(year_target) + \"-\" + tmp[\"_mmdd\"], errors=\"coerce\")\n",
    "    tmp = tmp.dropna(subset=[\"date_target\"]).copy()\n",
    "\n",
    "    tmp = (\n",
    "        tmp.drop(columns=[date_col, \"_mmdd\"])\n",
    "           .rename(columns={\"date_target\": \"date\", target_col: \"y_pred\"})\n",
    "    )\n",
    "    tmp[\"y_true\"] = np.nan\n",
    "    tmp[\"split_year\"] = year_target\n",
    "    tmp = tmp[[\"date\", cluster_col, \"y_true\", \"y_pred\", \"split_year\"]].sort_values([\"date\", cluster_col])\n",
    "    return tmp\n",
    "\n",
    "def compute_metrics_by_cluster(preds: pd.DataFrame, cluster_col: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for cl, g in preds.groupby(cluster_col, sort=False):\n",
    "        g_valid = g.dropna(subset=[\"y_true\"])\n",
    "        if g_valid.empty:\n",
    "            continue\n",
    "        y_true = g_valid[\"y_true\"].to_numpy(dtype=float)\n",
    "        y_pred = g_valid[\"y_pred\"].to_numpy(dtype=float)\n",
    "        rows.append({\n",
    "            cluster_col: cl, \"n_days\": len(g_valid),\n",
    "            \"MAE\": mae(y_true, y_pred), \"WAPE\": wape(y_true, y_pred), \"sMAPE\": smape(y_true, y_pred),\n",
    "        })\n",
    "    cols = [cluster_col, \"n_days\", \"MAE\", \"WAPE\", \"sMAPE\"]\n",
    "    return pd.DataFrame(rows, columns=cols).sort_values(cluster_col) if rows else pd.DataFrame(columns=cols)\n",
    "\n",
    "# ---------------------------- Orquestaci√≥n (sin returns) ---------------------------\n",
    "def _resolve_input_path(input_arg: Path) -> Path:\n",
    "    cand = Path(input_arg)\n",
    "    if cand.is_absolute() and cand.exists():\n",
    "        return cand\n",
    "    tried = []\n",
    "    bases = [ROOT_DIR, Path.cwd(), *ROOT_DIR.parents[:3]]\n",
    "    for base in bases:\n",
    "        p = (base / cand).resolve()\n",
    "        tried.append(p)\n",
    "        if p.exists():\n",
    "            return p\n",
    "    try:\n",
    "        hits = list(ROOT_DIR.rglob(cand.name))\n",
    "        for p in hits:\n",
    "            if p.is_file():\n",
    "                logging.warning(f\"Input no encontrado en rutas esperadas; usando hallazgo: {p}\")\n",
    "                return p\n",
    "    except Exception:\n",
    "        pass\n",
    "    msg = \" | \".join(str(x) for x in tried)\n",
    "    raise FileNotFoundError(\n",
    "        f\"No se encontr√≥ el dataset de entrada.\\n\"\n",
    "        f\"Argumento recibido: {input_arg}\\n\"\n",
    "        f\"Rutas intentadas: {msg}\\n\"\n",
    "        f\"Sugerencia: usa la ruta absoluta: {DEFAULT_INPUT}\"\n",
    "    )\n",
    "\n",
    "def run_like_script(input_path: Path,\n",
    "                    date_col: str,\n",
    "                    target_col: str,\n",
    "                    cluster_col: str,\n",
    "                    train_years: str,\n",
    "                    val_year: int,\n",
    "                    test_year: int,\n",
    "                    leap_fill: str = \"interp\",\n",
    "                    allow_missing_test: bool = True):\n",
    "    t_all = time.time()\n",
    "    ensure_dirs()\n",
    "\n",
    "    input_path = _resolve_input_path(Path(input_path))\n",
    "    logging.info(f\"Leyendo dataset: {input_path}\")\n",
    "    df = pd.read_parquet(input_path)\n",
    "\n",
    "    if not np.issubdtype(df[date_col].dtype, np.datetime64):\n",
    "        logging.info(f\"Parseando columna de fecha '{date_col}' a datetime.\")\n",
    "        df[date_col] = pd.to_datetime(df[date_col], utc=False, errors=\"coerce\")\n",
    "\n",
    "    if cluster_col not in df.columns:\n",
    "        aliases = [\"cluster_id\", \"cluster\", \"Cluster\", \"cluster_label\", \"clustername\", \"cluster_name\"]\n",
    "        found = next((c for c in aliases if c in df.columns), None)\n",
    "        if found is not None:\n",
    "            logging.warning(f\"Columna '{cluster_col}' no encontrada. Usando alias: '{found}'\")\n",
    "            cluster_col = found\n",
    "        else:\n",
    "            raise ValueError(f\"No se encontr√≥ la columna de cl√∫ster. Probados alias: {aliases}\")\n",
    "\n",
    "    check_columns(df, date_col, target_col, cluster_col)\n",
    "\n",
    "    years_present = sorted(df[date_col].dt.year.unique().tolist())\n",
    "    logging.info(f\"A√±os presentes en el dataset: {years_present}\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    agg_df = aggregate_cluster_daily(df, date_col=date_col, cluster_col=cluster_col, target_col=target_col)\n",
    "    logging.info(f\"Agregado cluster-d√≠a en {time.time()-t0:.2f}s (rows={len(agg_df):,}, \"\n",
    "                 f\"clusters={agg_df[cluster_col].nunique()})\")\n",
    "\n",
    "    needed_train_val = set([*(int(y) for y in train_years.split(\",\")), int(val_year)])\n",
    "    years_present_agg = set(agg_df[\"date\"].dt.year.unique().tolist())\n",
    "    if not needed_train_val.issubset(years_present_agg):\n",
    "        raise ValueError(f\"Faltan a√±os requeridos para train/val {sorted(list(needed_train_val))} en el agregado.\")\n",
    "\n",
    "    has_test_truth = int(test_year) in years_present_agg\n",
    "    if not has_test_truth and not allow_missing_test:\n",
    "        raise ValueError(\"No hay datos reales de test y 'allow_missing_test' est√° desactivado.\")\n",
    "\n",
    "    preds_val = seasonal_naive_predict_cluster_level(\n",
    "        agg_df=agg_df, year_target=int(val_year),\n",
    "        date_col=date_col, target_col=target_col, cluster_col=cluster_col, leap_fill=leap_fill\n",
    "    ).assign(split=\"validation\")\n",
    "\n",
    "    if has_test_truth:\n",
    "        preds_test = seasonal_naive_predict_cluster_level(\n",
    "            agg_df=agg_df, year_target=int(test_year),\n",
    "            date_col=date_col, target_col=target_col, cluster_col=cluster_col, leap_fill=leap_fill\n",
    "        ).assign(split=\"test\")\n",
    "    else:\n",
    "        preds_test = seasonal_naive_forecast_without_truth_cluster_level(\n",
    "            agg_df=agg_df, year_target=int(test_year),\n",
    "            date_col=date_col, target_col=target_col, cluster_col=cluster_col\n",
    "        ).assign(split=\"test\")\n",
    "        logging.warning(\"Predicciones de test generadas SIN y_true. M√©tricas de test se omiten.\")\n",
    "\n",
    "    metrics_val = compute_metrics_by_cluster(preds_val, cluster_col=cluster_col)\n",
    "    if not metrics_val.empty:\n",
    "        gv = preds_val.dropna(subset=[\"y_true\"])\n",
    "        global_val = pd.DataFrame([{\n",
    "            cluster_col: \"__GLOBAL__\", \"n_days\": gv.shape[0],\n",
    "            \"MAE\": mae(gv[\"y_true\"].to_numpy(), gv[\"y_pred\"].to_numpy()),\n",
    "            \"WAPE\": wape(gv[\"y_true\"].to_numpy(), gv[\"y_pred\"].to_numpy()),\n",
    "            \"sMAPE\": smape(gv[\"y_true\"].to_numpy(), gv[\"y_pred\"].to_numpy()),\n",
    "        }])\n",
    "        metrics_val = pd.concat([metrics_val, global_val], ignore_index=True)\n",
    "\n",
    "    if has_test_truth:\n",
    "        metrics_test = compute_metrics_by_cluster(preds_test, cluster_col=cluster_col)\n",
    "        if not metrics_test.empty:\n",
    "            gt = preds_test.dropna(subset=[\"y_true\"])\n",
    "            global_test = pd.DataFrame([{\n",
    "                cluster_col: \"__GLOBAL__\", \"n_days\": gt.shape[0],\n",
    "                \"MAE\": mae(gt[\"y_true\"].to_numpy(), gt[\"y_pred\"].to_numpy()),\n",
    "                \"WAPE\": wape(gt[\"y_true\"].to_numpy(), gt[\"y_pred\"].to_numpy()),\n",
    "                \"sMAPE\": smape(gt[\"y_true\"].to_numpy(), gt[\"y_pred\"].to_numpy()),\n",
    "            }])\n",
    "            metrics_test = pd.concat([metrics_test, global_test], ignore_index=True)\n",
    "    else:\n",
    "        metrics_test = pd.DataFrame()\n",
    "\n",
    "    if SAVE_OUTPUTS:\n",
    "        reports_dir = REPORTS_DIR / \"baselines\" / \"seasonal_naive\"\n",
    "        reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "        preds_val_path    = OUTPUTS_DIR / \"preds_val.parquet\"\n",
    "        preds_test_path   = OUTPUTS_DIR / \"preds_test.parquet\"\n",
    "        metrics_val_path  = reports_dir / \"metrics_validation.csv\"\n",
    "        metrics_test_path = reports_dir / \"metrics_test.csv\"\n",
    "        preds_val.to_parquet(preds_val_path, index=False)\n",
    "        preds_test.to_parquet(preds_test_path, index=False)\n",
    "        metrics_val.to_csv(metrics_val_path, index=False)\n",
    "        if not metrics_test.empty:\n",
    "            metrics_test.to_csv(metrics_test_path, index=False)\n",
    "        else:\n",
    "            logging.warning(\"No se exportan m√©tricas de TEST: no hay y_true.\")\n",
    "        logging.info(f\"Preds VAL ‚Üí {preds_val_path}\")\n",
    "        logging.info(f\"Preds TEST ‚Üí {preds_test_path}\")\n",
    "        logging.info(f\"M√©tricas VAL ‚Üí {metrics_val_path}\")\n",
    "        if not metrics_test.empty:\n",
    "            logging.info(f\"M√©tricas TEST ‚Üí {metrics_test_path}\")\n",
    "    else:\n",
    "        logging.info(\"SAVE_OUTPUTS=False ‚Üí No se guardan ficheros en disco.\")\n",
    "\n",
    "    logging.info(f\"OK Seasonal-Naive. Tiempo total: {time.time()-t_all:.2f}s\")\n",
    "\n",
    "# ---------------------------- Ejecuci√≥n (igual que script) -------------------------\n",
    "run_like_script(\n",
    "    input_path=ABS_INPUT if Path(ABS_INPUT).exists() else DEFAULT_INPUT,\n",
    "    date_col=\"date\",\n",
    "    target_col=\"sales_quantity\",\n",
    "    cluster_col=\"cluster_id\",\n",
    "    train_years=\"2022,2023\",\n",
    "    val_year=2024,\n",
    "    test_year=2025,\n",
    "    leap_fill=\"interp\",\n",
    "    allow_missing_test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8fc437f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>n_days</th>\n",
       "      <th>MAE</th>\n",
       "      <th>WAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>366</td>\n",
       "      <td>90.856557</td>\n",
       "      <td>0.057630</td>\n",
       "      <td>0.056217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>366</td>\n",
       "      <td>15.688525</td>\n",
       "      <td>0.065779</td>\n",
       "      <td>0.064650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>366</td>\n",
       "      <td>137.374317</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>0.075132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__GLOBAL__</td>\n",
       "      <td>1464</td>\n",
       "      <td>134.862705</td>\n",
       "      <td>0.070643</td>\n",
       "      <td>0.067208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>366</td>\n",
       "      <td>295.531421</td>\n",
       "      <td>0.076376</td>\n",
       "      <td>0.072833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_id  n_days         MAE      WAPE     sMAPE\n",
       "3           3     366   90.856557  0.057630  0.056217\n",
       "0           0     366   15.688525  0.065779  0.064650\n",
       "2           2     366  137.374317  0.070382  0.075132\n",
       "4  __GLOBAL__    1464  134.862705  0.070643  0.067208\n",
       "1           1     366  295.531421  0.076376  0.072833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar m√©tricas de validaci√≥n\n",
    "metrics_val = pd.read_csv(\n",
    "    r\"C:\\Users\\crisr\\Desktop\\M√°ster Data Science & IA\\PROYECTO\\PFM2_Asistente_Compras_Inteligente\\reports\\baselines\\seasonal_naive\\metrics_validation.csv\"\n",
    ")\n",
    "\n",
    "# Filtrar los cl√∫steres (excluir el global para el gr√°fico de barras)\n",
    "clusters = metrics_val[metrics_val[\"cluster_id\"] != \"__GLOBAL__\"]\n",
    "\n",
    "# Tabla ordenada por WAPE (puedes verla en el notebook directamente)\n",
    "display(metrics_val.sort_values(\"WAPE\"))\n",
    "\n",
    "# Gr√°fico comparativo WAPE y sMAPE por cl√∫ster\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(clusters[\"cluster_id\"].astype(str), clusters[\"WAPE\"], label=\"WAPE\", alpha=0.7)\n",
    "plt.bar(clusters[\"cluster_id\"].astype(str), clusters[\"sMAPE\"], label=\"sMAPE\", alpha=0.7)\n",
    "plt.axhline(metrics_val.loc[metrics_val[\"cluster_id\"]==\"__GLOBAL__\",\"WAPE\"].values[0],\n",
    "            color=\"red\", linestyle=\"--\", label=\"Global WAPE\")\n",
    "plt.title(\"Comparaci√≥n de WAPE y sMAPE por cl√∫ster (Validaci√≥n 2024)\")\n",
    "plt.xlabel(\"Cluster ID\")\n",
    "plt.ylabel(\"Error (%)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b536c7",
   "metadata": {},
   "source": [
    "üìä**Resultados del baseline *Seasonal Naive* (Validaci√≥n 2024)**.\n",
    "\n",
    "El baseline se evalu√≥ en el a√±o 2024 (validaci√≥n) usando 4 cl√∫steres de productos y se calcularon tres m√©tricas:  \n",
    "- **MAE (Mean Absolute Error)**: error absoluto medio en unidades de ventas.  \n",
    "- **WAPE (Weighted Absolute Percentage Error)**: error porcentual ponderado respecto al volumen real.  \n",
    "- **sMAPE (Symmetric Mean Absolute Percentage Error)**: error porcentual sim√©trico, robusto ante valores peque√±os.  \n",
    "\n",
    "üß© **Resultados por cl√∫ster**\n",
    "- **Cl√∫ster 0**: MAE bajo (~16 uds/d√≠a) y error relativo de 6.6%.  \n",
    "- **Cl√∫ster 1**: MAE alto (~296 uds/d√≠a) pero error relativo en torno al 7.6% (debido a su gran volumen de ventas).  \n",
    "- **Cl√∫ster 2**: MAE intermedio (~137 uds/d√≠a), WAPE ~7%.  \n",
    "- **Cl√∫ster 3**: MAE ~91 uds/d√≠a y el error relativo m√°s bajo, ~5.8%.  \n",
    "\n",
    "üåê **Resultado global**\n",
    "- **Global**: MAE ‚âà 135 uds/d√≠a, WAPE ‚âà 7%, sMAPE ‚âà 6.7%.  \n",
    "- Esto significa que, en promedio, el baseline reproduce **~93% de la demanda real** de 2024.  \n",
    "\n",
    "üìå **Conclusiones**\n",
    "1. El baseline *Seasonal Naive* ofrece un rendimiento **s√≥lido y estable**, con errores relativos bajos (5‚Äì7%).  \n",
    "2. Las diferencias en el MAE absoluto entre cl√∫steres reflejan su **volumen de ventas**, no una peor precisi√≥n relativa.  \n",
    "3. El resultado global (WAPE ‚âà 7%) constituye un **benchmark v√°lido**: cualquier modelo m√°s complejo debe superar este umbral para justificar su uso.  \n",
    "4. Este baseline proporciona una referencia clara y trazable del efecto de la estacionalidad pura sin variables ex√≥genas ni algoritmos avanzados.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29799b44",
   "metadata": {},
   "source": [
    "#### **8.2.3 Holt-Winters (ETS).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0f564",
   "metadata": {},
   "source": [
    "\n",
    "El m√©todo **Holt-Winters** (o **ETS: Error, Trend, Seasonality**) es una extensi√≥n del suavizado exponencial que modela de forma conjunta:\n",
    "- **Nivel**: estado base de la serie.\n",
    "- **Tendencia**: crecimiento o decrecimiento sistem√°tico.\n",
    "- **Estacionalidad**: patrones que se repiten de forma peri√≥dica.\n",
    "\n",
    "> A diferencia de un promedio m√≥vil, Holt-Winters **pondera m√°s las observaciones recientes**, lo que le permite adaptarse a cambios graduales en el nivel y la tendencia sin perder la estructura estacional.\n",
    "\n",
    "\n",
    "‚úèÔ∏è **Justificaci√≥n de uso en este proyecto**.\n",
    "- **Demanda con estacionalidad marcada** (ciclos anuales de ecommerce y picos por campa√±as).\n",
    "- **Flexibilidad** para capturar tanto **tendencias** como **estacionalidad** sin requerir un gran n√∫mero de hiperpar√°metros.\n",
    "- **Benchmark fuerte**: establece un list√≥n m√°s exigente que el Seasonal Naive para evaluar el beneficio de modelos cl√°sicos (SARIMAX) y de ML.\n",
    "\n",
    "\n",
    "üõ†Ô∏è  **Aplicaci√≥n (por cl√∫ster)**.\n",
    "- **Nivel de agregaci√≥n**: por **cl√∫ster** para alinear el baseline con el enfoque de modelado.\n",
    "- **Entrenamiento**: a√±os **2022‚Äì2023**.\n",
    "- **Validaci√≥n**: a√±o **2024**, para comparaci√≥n sistem√°tica de m√©tricas.\n",
    "- **Test**: a√±o **2025** completo (enero‚Äìdiciembre), para capturar todo el ciclo anual.\n",
    "- **Estacionalidad**: anual (periodicidad diaria). Nota: el valor del per√≠odo efectivo se ajustar√° respetando la frecuencia diaria y posibles matices del calendario (p. ej., bisiesto).\n",
    "\n",
    "\n",
    "üìè **M√©tricas y resultado esperado**.\n",
    "\n",
    "Se calcular√°n **MAE, WAPE y sMAPE** a nivel de cl√∫ster tanto en validaci√≥n (2024) como en test (2025).  \n",
    "\n",
    "\n",
    "> El resultado constituir√° un **benchmark exigente** frente al cual contrastar los modelos posteriores. Si un modelo no mejora de forma apreciable a Holt-Winters, su mayor complejidad **no estar√≠a justificada**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5302e",
   "metadata": {},
   "source": [
    "#### **8.2.4 Comparaci√≥n y conclusiones**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c4f0c1",
   "metadata": {},
   "source": [
    "### **8.3. Modelos cl√°sicos de series temporales.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cce699",
   "metadata": {},
   "source": [
    "### **8.4. Modelos de regresi√≥n y ML.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89414353",
   "metadata": {},
   "source": [
    "### **8.5. Backtesting y comparaci√≥n.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be9adef",
   "metadata": {},
   "source": [
    "### **8.6. Predicciones finales.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c9990",
   "metadata": {},
   "source": [
    "### **8.7. Conclusiones y l√≠neas futuras.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
